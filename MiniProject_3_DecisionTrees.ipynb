{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b8f25",
   "metadata": {},
   "source": [
    "#### Applied Machine Learning - Mini Project 3 (Tasnim Ahmed, ta1743)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afc8a4",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea39229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ba61a",
   "metadata": {},
   "source": [
    "### Creating the Decision Tree Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b63c88",
   "metadata": {},
   "source": [
    "Given the fact both of the datasets (iris and spambase) have continuous features we will implement decision trees that have binary splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f482b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node class - to create node with feature, threshold, branches and label details\n",
    "class Node: \n",
    "    def __init__(self, left = None, right = None, feature = None, threshold = None, label = None):\n",
    "        self.left = left              # left branch\n",
    "        self.right = right            # right branch\n",
    "        self.feature = feature        # on which feature was the node divided upon \n",
    "        self.threshold = threshold    # on what threshold of the feature was it divided upon\n",
    "        \n",
    "        self.label = label            # place the label if it is a tree node, else none\n",
    "        \n",
    "    def check_leaf_node(self):        # check is the node is a leaf (used later for traversal)\n",
    "        return self.label != None\n",
    "        \n",
    "    def label_value(self):        # return the label value if it is a leaf node\n",
    "        return self.label\n",
    "            \n",
    "        \n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, n_min):\n",
    "        self.root = None                # the root of the node\n",
    "        self.n_min = n_min              # the stopping criteria\n",
    "    \n",
    "    # function used for fitting the given data \n",
    "    def fit(self, X, y):               \n",
    "        min_sample_split = X.shape[0]*(self.n_min/100)     # set the stopping hyperparameter\n",
    "        self.root = self.grow_tree(X, y, min_sample_split) # get the root node after growing tree\n",
    "        \n",
    "    # recursive function to grow the tree based on threshold and min_sample_split\n",
    "    def grow_tree(self, X, y, min_sample_split):    \n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # checking the stopping criteria \n",
    "        if (n_samples <= min_sample_split or n_labels == 1):\n",
    "            # find the max label of the dataset and set that as the leaf node value\n",
    "            leaf_node = Node(label = self.max_label(y.to_numpy()))\n",
    "            return leaf_node   \n",
    "           \n",
    "        # get the best feature and threshold value that splits the given dataset\n",
    "        split_feature, split_threshold = self.find_best_split(X, y, n_features)\n",
    "        \n",
    "        # create child nodes\n",
    "        X_col = X.iloc[:, split_feature]\n",
    "        left_ind = np.argwhere(X_col.to_numpy() <= split_threshold).flatten() # get the left branch indices\n",
    "        right_ind = np.argwhere(X_col.to_numpy() > split_threshold).flatten() # get the right branch indices\n",
    "        \n",
    "        # divide the X and y based on the indices for left and right branches \n",
    "        X_left, y_left = X.iloc[left_ind], y.iloc[left_ind]     \n",
    "        X_right, y_right = X.iloc[right_ind], y.iloc[right_ind]\n",
    "        \n",
    "        # call the grow tree function again on the left and right branches\n",
    "        left_node = self.grow_tree(X_left, y_left, min_sample_split)\n",
    "        right_node = self.grow_tree(X_right, y_right, min_sample_split)\n",
    "        \n",
    "        # return the node with feature value, threshold value and its branches \n",
    "        return Node(left_node, right_node,  split_feature, split_threshold)\n",
    "      \n",
    "    \n",
    "    # iterates through the columns of the given dataset to find the best split\n",
    "    def find_best_split(self, X, y, n_features):\n",
    "        max_ig = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        for i in range(n_features):              # iterate over the columnns \n",
    "            X_col = X.iloc[:, i]                 # extract the column with index i\n",
    "            max_col_ig, max_col_thr = self.col_information_gain(X_col, y)# get the max ig and thresh of column[i]\n",
    "            \n",
    "            if max_col_ig > max_ig:  # find the best ig and thresh amongst all the columns of X\n",
    "                max_ig = max_col_ig\n",
    "                best_feature = i\n",
    "                best_threshold = max_col_thr\n",
    "        \n",
    "        # return the best feature value and threshold of the column that has highest information gain\n",
    "        return best_feature, best_threshold\n",
    "        \n",
    "    \n",
    "    # used for labelling the leaf node - finds the most common label amonst the y \n",
    "    def max_label(self, y):\n",
    "        labels = np.unique(y)\n",
    "        n_labels = len(labels)\n",
    "        label_dict = {}\n",
    "        \n",
    "        # initiated the dictionary pairs {labelX: 0}\n",
    "        for i in range(n_labels):\n",
    "            label_dict[labels[i]] = 0\n",
    "        \n",
    "        # iterates over the y and counts each label and adds it to the dictionary\n",
    "        for i in range(n_labels):\n",
    "            for j in range(len(y)):\n",
    "                if y[j] == labels[i]:\n",
    "                    label_dict[labels[i]] += 1\n",
    "                    \n",
    "        #find the max label and return that    \n",
    "        return max(label_dict, key = label_dict.get)\n",
    "    \n",
    "    # entropy formula - find the level of disorder of a dataset\n",
    "    def entropy(self, column):\n",
    "        counts = np.bincount(column)  # counts the number of labels in the given y column\n",
    "        probs = counts/len(column)    # the probability of each label in the y column\n",
    "        entropy = np.sum([p*math.log(p, 2) for p in probs if p > 0])  # calculate the entropy (before negation)\n",
    "        return -entropy    # negate and return the value\n",
    "    \n",
    "    # measure the reduction in entropy of a split\n",
    "    def information_gain(self, X_col, y, threshold):\n",
    "        # calculate the original entropy of the target before split\n",
    "        main_entropy = self.entropy(y)\n",
    "        \n",
    "        # creating the branch splits based on the threshold\n",
    "        splits =  self.split_dataset(X_col, y, threshold)\n",
    "        branch_splits = [splits[0], splits[1]]\n",
    "        target_splits = [splits[2], splits[3]]\n",
    "        \n",
    "        \n",
    "        # sum the entropies*prob of the child branches\n",
    "        sub = 0\n",
    "        for i in range(len(branch_splits)):\n",
    "            prob = len(branch_splits[i])/len(X_col)\n",
    "            sub += prob*self.entropy(target_splits[i])\n",
    "            \n",
    "        # subtract from the main_entropy and return the value                            \n",
    "        return main_entropy - sub\n",
    "    \n",
    "    # splits the dataset using the threshold into left and right branches\n",
    "    def split_dataset(self, X_col, y, threshold):    \n",
    "        \n",
    "        left_split, left_target, right_split, right_target = [], [], [], []\n",
    "        \n",
    "        #Split the data based on the threshold \n",
    "        for i in range(len(X_col)):\n",
    "            # get the rows less than the threshold - left branch\n",
    "            if X_col[i] <= threshold:\n",
    "                left_split.append(X_col[i]) \n",
    "                left_target.append(y[i])\n",
    "            # get the rows more than or equal to the threshold - right branch\n",
    "            else:\n",
    "                right_split.append(X_col[i])\n",
    "                right_target.append(y[i])\n",
    "    \n",
    "        return [left_split, right_split, left_target, right_target]\n",
    "    \n",
    "    # calculates the information gain for each column \n",
    "    def col_information_gain(self, X_col, y):\n",
    "        X_col = X_col.to_numpy()   # converts to numpy array for indexing\n",
    "        y = y.to_numpy()           # converts to numpy array for indexing\n",
    "        \n",
    "        # dictionary that stores the theshold values with the information gain {threshold: ig}\n",
    "        col_igs = {}\n",
    "        max_ig, max_threshold = None, None\n",
    "        \n",
    "        for i in range(len(X_col) - 1):\n",
    "            # calculate the average of adjacent row values\n",
    "            avg_thr = (X_col[i] + X_col[i+1])/2\n",
    "\n",
    "            # get the information gain and add it to the dictionary \n",
    "            col_igs[avg_thr] = self.information_gain(X_col, y, avg_thr)\n",
    "            \n",
    "            # get the max threshold value (the key) from the dictionary\n",
    "            max_threshold = max(col_igs, key=col_igs.get)\n",
    "            max_ig = col_igs.get(max_threshold)    # get the value of the max key\n",
    "\n",
    "        return max_ig, max_threshold\n",
    "    \n",
    "    # predicts y value by traversing the tree that was created by the growing tree function \n",
    "    def predict_y(self, X):\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            X_row = X.iloc[i]\n",
    "            y_pred.append(self.traverse_tree(X_row, self.root))  # append the predicted value to the array\n",
    "        \n",
    "        # returns the predicted values as an array\n",
    "        return y_pred\n",
    "           \n",
    "    # traverses the tree recursively until it reaches a leaf node\n",
    "    def traverse_tree(self, X, node):   \n",
    "        if node.check_leaf_node():  # if the node is leas node then it stop traversing and returns the label\n",
    "            return node.label\n",
    "        \n",
    "        # if the value is greater then the threshold then it goes to the right branch\n",
    "        if X.iloc[node.feature] > node.threshold:\n",
    "            return self.traverse_tree(X, node.right)\n",
    "        # else go to the left branch\n",
    "        return self.traverse_tree(X, node.left)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b3f47",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc47715f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0   f1   f2   f3       target\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "iris_data  = pd.read_csv(\"iris.csv\", names = [\"f0\", \"f1\", \"f2\", \"f3\", \"target\"])\n",
    "# Verifying if the data has been loaded properly\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3921d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data\n",
    "iris_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d586ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and the target variable columns\n",
    "X = iris_data.drop('target', axis = 'columns') #independent variables\n",
    "y = iris_data['target']  #dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a270a8",
   "metadata": {},
   "source": [
    "### Relabelling The y Values For Fitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f41f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the species values to 0, 1 and 2\n",
    "y_labelled = []\n",
    "for i in y:\n",
    "    if i == \"Iris-setosa\": \n",
    "        y_labelled.append(0)\n",
    "        \n",
    "    elif i == \"Iris-versicolor\":\n",
    "        y_labelled.append(1)\n",
    "        \n",
    "    else:\n",
    "        y_labelled.append(2)\n",
    "\n",
    "# convertint the array to panda dataframe\n",
    "y_labelled = (pd.DataFrame(y_labelled)).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e57486",
   "metadata": {},
   "source": [
    "### Fitting The Model and Predicting y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dccf1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score    # importing accuracy for model performance calculation\n",
    "from sklearn.model_selection import KFold     # importing KFold for splitting the data into training & testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79536e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "kfold_value = 10   # number of folds used for splitting\n",
    "kfold = KFold(n_splits = kfold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af0670dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mins = [5, 10, 15, 20]     # early stopping strategy values\n",
    "                             # used in the DecisionTree Object to calculate the min number of rows need in \n",
    "                             # a dataset to stop the tree from growing\n",
    "\n",
    "n_min_accuracy = []  # average accuracy of the model for each n_min values\n",
    "all_accs = []        # accuracy of each iteration, within each fold (used for calculating standard deviation)\n",
    "\n",
    "for n_min in n_mins: # iterate over all the n_min value\n",
    "    \n",
    "    fold_accuracy = []  # stores the accuracies of a fold\n",
    "    for train, test in kfold.split(X):\n",
    "        # Split the dataset into training and test set\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]  \n",
    "        y_train, y_test = y_labelled.iloc[train], y_labelled.iloc[test]\n",
    "        \n",
    "        dt_iris = DecisionTreeClassifier(n_min)  # create the DecisionTree object with a n_min value\n",
    "        dt_iris.fit(X_train, y_train)            # fit the model with training set\n",
    "        y_pred = dt_iris.predict_y(X_test)       # predict y-test value with the fitted model\n",
    "        \n",
    "        # append the accuracy of each iteration of the folds\n",
    "        fold_accuracy.append(accuracy_score(y_test, y_pred)) \n",
    "        \n",
    "    # append the fold_accuracies separately for each n_min value\n",
    "    all_accs.append(fold_accuracy)  \n",
    "    # calculate the average accuracy of each n_min and append it\n",
    "    n_min_accuracy.append(round(np.average(fold_accuracy), 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb65142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation across the fold\n",
    "n_min_stds = []\n",
    "for i in range(len(all_accs)):\n",
    "    # calculate the standard deviation\n",
    "    std = np.sqrt(np.sum((all_accs[i] - np.average(all_accs[i]))**2)/len(all_accs[i]))\n",
    "    # append it to the array\n",
    "    n_min_stds.append(round(std,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484bacc4",
   "metadata": {},
   "source": [
    "### Summarized Performance Of The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5469bc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_min Values</th>\n",
       "      <th>Average</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_min Values  Average  Standard Deviation\n",
       "0             5     0.95               0.058\n",
       "1            10     0.93               0.073\n",
       "2            15     0.93               0.073\n",
       "3            20     0.93               0.073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the Model: 0.935\n"
     ]
    }
   ],
   "source": [
    "# create the table with the average and standard deviation of the accuracies of each n_min value\n",
    "iris_report = pd.DataFrame(list(zip(n_mins, n_min_accuracy, n_min_stds)), index = None, columns = [\"n_min Values\", \"Average\", \"Standard Deviation\"])\n",
    "display(iris_report)\n",
    "\n",
    "print(\"Overall Accuracy of the Model:\", np.average(n_min_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb8c78",
   "metadata": {},
   "source": [
    "## Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec98cebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3     4     5     6     7     8     9  ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  target  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278       1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028       1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259       1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191       1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191       1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "spam_data  = pd.read_csv(\"spambase.csv\", header = None)\n",
    "spam_data.columns = [*spam_data.columns[:-1], 'target']\n",
    "# Verifying if the data has been loaded properly\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67a50ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data to make sure it loaded properly\n",
    "spam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1fbb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and the target variable columns\n",
    "X_spam = spam_data.drop('target', axis = 'columns') #independent variables\n",
    "y_spam = spam_data['target']  #dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f44363",
   "metadata": {},
   "source": [
    "### Fitting The Model and Predicting y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5181a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_s = KFold(n_splits = kfold_value)\n",
    "\n",
    "n_min_spam = []  # average accuracy of the model for each n_min values\n",
    "all_accs_spam = []      # accuracy of each iteration, within each fold (used for calculating standard deviation)\n",
    "\n",
    "for n_min in n_mins: # iterate over all the n_min value (used from above)\n",
    "    \n",
    "    fold_accuracy = []  # stores the accuracies of a fold\n",
    "    for train, test in kfold_s.split(X_spam):\n",
    "        # Split the dataset into training and test set\n",
    "        X_train, X_test = X_spam.iloc[train], X_spam.iloc[test]  \n",
    "        y_train, y_test = y_spam.iloc[train], y_spam.iloc[test]\n",
    "        \n",
    "        dt_spam = DecisionTreeClassifier(n_min)  # create the DecisionTree object with a n_min value\n",
    "        dt_spam.fit(X_train, y_train)            # fit the model with training set\n",
    "        y_pred = dt_spam.predict_y(X_test)       # predict y-test value with the fitted model\n",
    "        \n",
    "        # append the accuracy of each iteration of the folds\n",
    "        fold_accuracy.append(accuracy_score(y_test, y_pred)) \n",
    "        \n",
    "    # append the fold_accuracies separately for each n_min value\n",
    "    all_accs_spam.append(fold_accuracy)  \n",
    "    # calculate the average accuracy of each n_min and append it\n",
    "    n_min_spam.append(round(np.average(fold_accuracy), 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f52a17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation across the fold\n",
    "n_min_stds_spam = []\n",
    "for i in range(len(all_accs_spam)):\n",
    "    # calculate the standard deviation\n",
    "    std = np.sqrt(np.sum((all_accs_spam[i] - np.average(all_accs_spam[i]))**2)/len(all_accs_spam[i]))\n",
    "    # append it to the array\n",
    "    n_min_stds_spam.append(round(std,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f90e3",
   "metadata": {},
   "source": [
    "### Summarized Performance Of The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67696248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_min Values</th>\n",
       "      <th>Average</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_min Values  Average  Standard Deviation\n",
       "0             5     0.88               0.065\n",
       "1            10     0.88               0.064\n",
       "2            15     0.84               0.074\n",
       "3            20     0.83               0.099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the Model: 0.8575\n"
     ]
    }
   ],
   "source": [
    "spam_report = pd.DataFrame(list(zip(n_mins, n_min_spam, n_min_stds_spam)), index = None, columns = [\"n_min Values\", \"Average\", \"Standard Deviation\"])\n",
    "display(spam_report)\n",
    "\n",
    "print(\"Overall Accuracy of the Model:\", np.average(n_min_spam))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
