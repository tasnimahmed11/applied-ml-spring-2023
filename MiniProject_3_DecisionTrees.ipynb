{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b8f25",
   "metadata": {},
   "source": [
    "#### Applied Machine Learning - Mini Project 2 (Tasnim Ahmed, ta1743)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afc8a4",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a89fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node - feature attribute (does the item meet the specific category)\n",
    "# branches - decision (rule - yes or no)\n",
    "# leaf - an outcome (the category - leaf name or spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea39229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b63c88",
   "metadata": {},
   "source": [
    "Given the fact both of the datasets have continuous features we will implement decision trees that have binary splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f482b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(self, left = None, right = None, feature = None, threshold = None, label = None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = feature        # on which feature was the node divided upon \n",
    "        self.threshold = threshold    # on what threshold of the feature was it divided upon\n",
    "        \n",
    "        self.label = label            # place the label if it is a tree node, else none\n",
    "        \n",
    "        def check_leaf_node(self):\n",
    "            return self.label != None\n",
    "        \n",
    "        def label_value(self):        # return the label value if it is a leaf node\n",
    "            return self.label\n",
    "            \n",
    "        \n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, n_min, n_features):\n",
    "        self.root = None                # the root of the node\n",
    "        self.n_min = n_min              # the stopping criteria\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #set the stopping hyperparameter\n",
    "        min_sample_split = X.shape[0]*(self.n_min/100)\n",
    "        self.root = self.grow_tree(X, y, min_sample_split)\n",
    "        \n",
    "    def grow_tree(self, X, y, min_sample_split):    #recursive function\n",
    "        sample_size, n_features = X.shape\n",
    "        labels = np.unique(y)\n",
    "        n_labels = len(labels)\n",
    "        \n",
    "        # checking the stopping criteria \n",
    "        if (n_samples <= min_sample_split or n_labels == 1):\n",
    "            #find the max label of the dataset and set that as the leaf node value\n",
    "            leaf_node = Node(label = max_label(y))\n",
    "            return leaf_node   #return?\n",
    "           \n",
    "        # get the best feature split and threshold for the given dataset\n",
    "        split_feature, split_threshold = find_best_split(X, y, n_features)\n",
    "        \n",
    "        # create child nodes\n",
    "        # call the grow tree function again on the subset of the data\n",
    "        \n",
    "        return root\n",
    "      \n",
    "    # find the best split (threshold and feature) upon which the given dataset will be separated\n",
    "    def find_best_split(self, X, y):\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        col_ig_dict = {}\n",
    "        \n",
    "        # iterate over the columnns \n",
    "        for i in range(n_features):\n",
    "            #get the max ig value and threshold value for each column and store in the dict\n",
    "            #INCOMPLETE\n",
    "            #send column X[, i] to col_information_gain function\n",
    "            #store those values in the dict\n",
    "            col_ig_dict[i] = 0\n",
    "    \n",
    "        #the feature with highest information gain is selected as the best one \n",
    "        best_threshold = max(col_ig_dict, key=col_ig.get)\n",
    "        best_feature = col_ig_dict.get(best_threshold)\n",
    "                \n",
    "        return best_feature, best_threshold\n",
    "        \n",
    "    \n",
    "    def max_label(self, y):\n",
    "        labels = np.unique(y)\n",
    "        n_labels = len(labels)\n",
    "        label_dict = {}\n",
    "        \n",
    "        for i in range(n_labels):\n",
    "            label_dict[labels[i]] = 0\n",
    "        \n",
    "        for i in range(n_labels):\n",
    "            for j in range(len(y)):\n",
    "                if y[j] == labels[i]:\n",
    "                    label_dict[labels[i]] += 1\n",
    "                    \n",
    "        #find the max label and return that    \n",
    "        label = max(label_dict, key = label_dict.get)\n",
    "        return label\n",
    "    \n",
    "    def entropy(self, column):\n",
    "        counts = np.bincount(column)\n",
    "        entropy = 0\n",
    "        for count in counts:\n",
    "            if (count/len(column)) > 0:\n",
    "                entropy += (count/len(column))*math.log(count/len(column, 2))                               \n",
    "        return entropy  \n",
    "    \n",
    "    \n",
    "    def information_gain(self, X_col, y, threshold):\n",
    "        #calculate the original entropy of the target before split\n",
    "        main_entropy = entropy(y)\n",
    "        \n",
    "        #Split the data based on the threshold  \n",
    "        left_split = left_target = right_split = right_target = []\n",
    "        for i in range(len(X_col)):\n",
    "            # get the rows less than the threshold\n",
    "            if X_col[i] < threshold:\n",
    "                left_split.append(X_col[i])\n",
    "                left_target.append(y[i])\n",
    "            # get the rows more than or equal to the threshold\n",
    "            else:\n",
    "                right_split.append(X_col[i])\n",
    "                right_target.append(y[i])\n",
    "    \n",
    "        splits = [left_split, right_split]\n",
    "        target_splits = [left_target, right_target]\n",
    "        to_sub = 0\n",
    "        \n",
    "        for i in range(len(splits)):\n",
    "            prob = len(splits[i])/len(X_col)\n",
    "            to_sub += prob*entropy(target_splits[i])\n",
    "                                     \n",
    "        return main_entropy - sub\n",
    "        \n",
    "    def col_information_gain(self, X_col, y):\n",
    "        # dictionary that stores the theshold values with the information gain {threshold: ig}\n",
    "        col_igs = {}\n",
    "        \n",
    "        # iterate over the rows\n",
    "        for i in range(len(X_col) - 1):\n",
    "            # calculate the average of adjacent row values\n",
    "            avg_thr = (X_col[i] + X_col[i+1])/2\n",
    "            # get the information gain and add it to the dictionary \n",
    "            col_igs[avg_thr] = information_gain(X_col, y, avg_thr)\n",
    "        \n",
    "        max_threshold = max(col_ig, key=col_ig.get)\n",
    "        max_ig = col_igs.get(max_threshold)\n",
    "                                                    \n",
    "        return {max_ig, max_threshold}\n",
    "    \n",
    "    def predict_y(self, X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b45590",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [1,0,1,1,1,0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b3f47",
   "metadata": {},
   "source": [
    "## Iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6cf0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has three class - label them as yes. no or maybe\n",
    "# predict the classes given 4 features - length and width of sepals and petals\n",
    "# 150 instance, each class having 50 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc47715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "iris_data  = pd.read_csv(\"iris.csv\", names = [\"f1\", \"f2\", \"f3\", \"f4\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba8d3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   f3   f4       target\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying if the data has been loaded properly\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3921d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data\n",
    "iris_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d586ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f1' 'f2' 'f3' 'f4']\n",
      "(150,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7707bd7ecba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# Separating the features and the target variable columns\n",
    "X = iris_data.drop('target', axis = 'columns') #independent variables\n",
    "y = iris_data['target']  #dependent variable\n",
    "\n",
    "rows, cols = X.shape\n",
    "print(X.columns.values)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f41f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the species values to 0, 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0670dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy with kfold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb8c78",
   "metadata": {},
   "source": [
    "## Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through thr decision tree with kfold and n_min array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67696248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
