{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b8f25",
   "metadata": {},
   "source": [
    "#### Applied Machine Learning - Mini Project 2 (Tasnim Ahmed, ta1743)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afc8a4",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a89fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node - feature attribute (does the item meet the specific category)\n",
    "# branches - decision (rule - yes or no)\n",
    "# leaf - an outcome (the category - leaf name or spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea39229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b63c88",
   "metadata": {},
   "source": [
    "Given the fact both of the datasets have continuous features we will implement decision trees that have binary splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6f482b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(self, left = None, right = None, feature = None, threshold = None, label = None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = feature        # on which feature was the node divided upon \n",
    "        self.threshold = threshold    # on what threshold of the feature was it divided upon\n",
    "        \n",
    "        self.label = label            # place the label if it is a tree node, else none\n",
    "        \n",
    "    def check_leaf_node(self):\n",
    "        return self.label != None\n",
    "        \n",
    "    def label_value(self):        # return the label value if it is a leaf node\n",
    "        return self.label\n",
    "            \n",
    "        \n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, n_min):\n",
    "        self.root = None                # the root of the node\n",
    "        self.n_min = n_min              # the stopping criteria\n",
    "    \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #set the stopping hyperparameter\n",
    "        min_sample_split = X.shape[0]*(self.n_min/100)\n",
    "        self.root = self.grow_tree(X, y, min_sample_split)\n",
    "        \n",
    "\n",
    "    def grow_tree(self, X, y, min_sample_split):    #recursive function\n",
    "        n_samples, n_features = X.shape\n",
    "        labels = np.unique(y)\n",
    "        n_labels = len(labels)\n",
    "        \n",
    "        # checking the stopping criteria \n",
    "        if (n_samples <= min_sample_split or n_labels == 1):\n",
    "            #find the max label of the dataset and set that as the leaf node value\n",
    "            leaf_node = Node(label = self.max_label(y.to_numpy()))\n",
    "            return leaf_node   \n",
    "           \n",
    "        # get the best feature split and threshold for the given dataset\n",
    "        split_feature, split_threshold = self.find_best_split(X, y, n_features)\n",
    "        \n",
    "        # create child nodes\n",
    "        X_col = X.iloc[:, split_feature]\n",
    "        left_ind = np.argwhere(X_col.to_numpy() < split_threshold).flatten() \n",
    "        right_ind = np.argwhere(X_col.to_numpy() >= split_threshold).flatten() \n",
    "        \n",
    "        X_left, y_left = X.iloc[left_ind], y.iloc[left_ind]\n",
    "        X_right, y_right = X.iloc[right_ind], y.iloc[right_ind]\n",
    "        \n",
    "        # call the grow tree function again on the subset of the data\n",
    "        left_node = self.grow_tree(X_left, y_left, min_sample_split)\n",
    "        right_node = self.grow_tree(X_right, y_right, min_sample_split)\n",
    "             \n",
    "        return Node(left_node, right_node,  split_feature, split_threshold)\n",
    "      \n",
    "        \n",
    "    def find_best_split(self, X, y, n_features):\n",
    "        max_ig = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        for i in range(n_features):              # iterate over the columnns \n",
    "            X_col = X.iloc[:, i]                 # extract the column with index i\n",
    "            max_col_ig, max_col_thr = self.col_information_gain(X_col, y) # get the max ig and thr of column[i]\n",
    "            \n",
    "            if max_col_ig > max_ig:\n",
    "                max_ig = max_col_ig\n",
    "                best_feature = i\n",
    "                best_threshold = max_col_thr\n",
    "                \n",
    "        return best_feature, best_threshold\n",
    "        \n",
    "    \n",
    "    def max_label(self, y):\n",
    "        labels = np.unique(y)\n",
    "        n_labels = len(labels)\n",
    "        label_dict = {}\n",
    "        \n",
    "        for i in range(n_labels):\n",
    "            label_dict[labels[i]] = 0\n",
    "        \n",
    "        for i in range(n_labels):\n",
    "            for j in range(len(y)):\n",
    "                if y[j] == labels[i]:\n",
    "                    label_dict[labels[i]] += 1\n",
    "                    \n",
    "        #find the max label and return that    \n",
    "        return max(label_dict, key = label_dict.get)\n",
    "    \n",
    "    \n",
    "    def entropy(self, column):\n",
    "        counts = np.bincount(column)\n",
    "        probs = counts/len(column)\n",
    "        entropy = np.sum([p*math.log(p, 2) for p in probs if p > 0])\n",
    "        return -entropy\n",
    "    \n",
    "    \n",
    "    def information_gain(self, X_col, y, threshold):\n",
    "        # calculate the original entropy of the target before split\n",
    "        main_entropy = self.entropy(y)\n",
    "        \n",
    "        # creating the branch splits based on the threshold\n",
    "        splits =  self.split_dataset(X_col, y, threshold)\n",
    "        branch_splits = [splits[0], splits[1]]\n",
    "        target_splits = [splits[2], splits[3]]\n",
    "        \n",
    "        #do I need to check the lenght of the splits to return 0? because there will be math error right?\n",
    "        \n",
    "        \n",
    "        # sum the entropies*prob of the child branches\n",
    "        sub = 0\n",
    "        for i in range(len(branch_splits)):\n",
    "            prob = len(branch_splits[i])/len(X_col)\n",
    "            sub += prob*self.entropy(target_splits[i])\n",
    "                                     \n",
    "        return main_entropy - sub\n",
    "    \n",
    "    \n",
    "    def split_dataset(self, X_col, y, threshold):    #there should be changes here\n",
    "        \n",
    "        left_split, left_target, right_split, right_target = [], [], [], []\n",
    "        \n",
    "        #Split the data based on the threshold \n",
    "        for i in range(len(X_col)):\n",
    "            # get the rows less than the threshold\n",
    "            if X_col[i] < threshold:\n",
    "                left_split.append(X_col[i]) \n",
    "                left_target.append(y[i])\n",
    "            # get the rows more than or equal to the threshold\n",
    "            else:\n",
    "                right_split.append(X_col[i])\n",
    "                right_target.append(y[i])\n",
    "    \n",
    "        return [left_split, right_split, left_target, right_target]\n",
    "    \n",
    "        \n",
    "    def col_information_gain(self, X_col, y):\n",
    "        # dictionary that stores the theshold values with the information gain {threshold: ig}\n",
    "        X_col = X_col.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        col_igs = {}\n",
    "        max_ig, max_threshold = None, None\n",
    "        \n",
    "        for i in range(len(X_col) - 1):\n",
    "            # calculate the average of adjacent row values\n",
    "            avg_thr = (X_col[i] + X_col[i+1])/2\n",
    "\n",
    "            # get the information gain and add it to the dictionary \n",
    "            col_igs[avg_thr] = self.information_gain(X_col, y, avg_thr)\n",
    "\n",
    "            max_threshold = max(col_igs, key=col_igs.get)\n",
    "            max_ig = col_igs.get(max_threshold)\n",
    "\n",
    "        return max_ig, max_threshold\n",
    "    \n",
    "    \n",
    "    def predict_y(self, X):\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            X_row = X.iloc[i]\n",
    "            y_pred.append(self.traverse_tree(X_row, self.root))\n",
    "            \n",
    "        return y_pred\n",
    "           \n",
    "    \n",
    "    def traverse_tree(self, X, node):   #recursive function\n",
    "        if node.check_leaf_node():\n",
    "            return node.label\n",
    "        \n",
    "        if X.iloc[node.feature] >= node.threshold:\n",
    "            return self.traverse_tree(X, node.right)\n",
    "        return self.traverse_tree(X, node.left)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b3f47",
   "metadata": {},
   "source": [
    "## Iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fc47715f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   f3   f4       target\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "iris_data  = pd.read_csv(\"iris.csv\", names = [\"f0\", \"f1\", \"f2\", \"f3\", \"target\"])\n",
    "# Verifying if the data has been loaded properly\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3921d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data\n",
    "iris_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9d586ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features and the target variable columns\n",
    "X = iris_data.drop('target', axis = 'columns') #independent variables\n",
    "y = iris_data['target']  #dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f9f41f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the species values to 0, 1 and 2\n",
    "y_labelled = []\n",
    "for i in y:\n",
    "    if i == \"Iris-setosa\": \n",
    "        y_labelled.append(0)\n",
    "        \n",
    "    elif i == \"Iris-versicolor\":\n",
    "        y_labelled.append(1)\n",
    "        \n",
    "    else:\n",
    "        y_labelled.append(2)\n",
    "              \n",
    "y_labelled = (pd.DataFrame(y_labelled)).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "dccf1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "79536e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "kfold_value = 10\n",
    "kfold = KFold(n_splits = kfold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "af0670dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9266666666666667, 0.9200000000000002, 0.9200000000000002, 0.9200000000000002]\n"
     ]
    }
   ],
   "source": [
    "n_mins = [5, 10, 15, 20]\n",
    "\n",
    "n_min_accuracy = []\n",
    "for n in n_mins:\n",
    "    \n",
    "    fold_accuracy = []\n",
    "    for train, test in kfold.split(X):\n",
    "        # Split the dataset into training and test set\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]  \n",
    "        y_train, y_test = y_labelled.iloc[train], y_labelled.iloc[test]\n",
    "        \n",
    "        dt_iris = DecisionTreeClassifier(n)\n",
    "        dt_iris.fit(X_train, y_train)\n",
    "        y_pred = dt_iris.predict_y(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        fold_accuracy.append(acc)\n",
    "        \n",
    "    n_min_accuracy.append(np.average(fold_accuracy))\n",
    "     \n",
    "\n",
    "print(n_min_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb8c78",
   "metadata": {},
   "source": [
    "## Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through thr decision tree with kfold and n_min array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67696248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
