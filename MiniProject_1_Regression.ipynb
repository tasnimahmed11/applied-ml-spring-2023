{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82b5e01",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815741ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50045f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68598fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     #X, y = load_boston(return_X_y=True)\n",
    "     boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa7753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data in a dataframe for readability\n",
    "df_boston = pd.DataFrame(boston.data, columns=boston.feature_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad847b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47f3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f987590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston['PRICE'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e703c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()  #after adding the price label to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690685c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c68907",
   "metadata": {},
   "source": [
    "Based on the information below we can tell that there no non-empty cells, thus, we  don't need to pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d5c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  PRICE    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms of the dataset?\n",
    "#Do we take off the features that don't correlate with the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d5699",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db033bd3",
   "metadata": {},
   "source": [
    "### Splitting Data: Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f664827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_boston.drop('PRICE', axis = 'columns') #independent variables\n",
    "y = df_boston['PRICE']  #dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "78eb93ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending ones to the matrix of independendent variable\n",
    "X = np.append(arr = np.ones([X.shape[0], 1]).astype(int), values = X, axis= 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bc4f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold_value = 5\n",
    "kfold = KFold(n_splits = kfold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1bbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What metric should we use to estimate the performance of our linear regression model?\n",
    " \n",
    "#loss {train, validation, test}, accuracy {train, validation, test},\n",
    "#confusion matrix, precision, recall, f1 score, etc. \n",
    "#Many to choose from but check the lab manual for specifics requested per question.\n",
    "\n",
    "\n",
    "#find error - then square it - then mean \n",
    "#yhat = theta * independentvariabel\n",
    "#np.matmul // np.dot(does the same thing upto 2 dimension)\n",
    "#scale th data - preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c3605",
   "metadata": {},
   "source": [
    "### *Closed form solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2015097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta\n",
    "\n",
    "def predict_y(X, theta):\n",
    "    return np.dot(X,theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffdda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training MSE: 20.735084629886188\n",
      "Average testing MSE: 37.131807467699446\n"
     ]
    }
   ],
   "source": [
    "mse_train_arr = []\n",
    "mse_test_arr = []\n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    theta = normal_equation(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = (sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_train_arr.append(mse_train)\n",
    "    \n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = (sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_test_arr.append(mse_test)\n",
    "\n",
    "\n",
    "avg_train = np.mean(mse_train_arr)\n",
    "avg_test = np.mean(mse_test_arr)\n",
    "print(\"Average training MSE:\", avg_train)\n",
    "print(\"Average testing MSE:\", avg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b49cc",
   "metadata": {},
   "source": [
    "### *Ridge Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9233f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_theta(X, y, alpha):\n",
    "    I = np.identity(X.shape[1])\n",
    "    I[0][0] = 0  \n",
    "    theta = np.linalg.inv(X.T.dot(X) + alpha*I).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d56dbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10.0 MSE train = 4.63254342637088 and MSE test = 5.518166280868784 \n",
      "\n",
      "For alpha = 31.622776601683793 MSE train = 4.660283682305299 and MSE test = 5.467538413292376 \n",
      "\n",
      "For alpha = 100.0 MSE train = 4.712657472293112 and MSE test = 5.421555485018982 \n",
      "\n",
      "For alpha = 316.22776601683796 MSE train = 4.790315495620764 and MSE test = 5.411757151120624 \n",
      "\n",
      "For alpha = 1000.0 MSE train = 4.886169923351052 and MSE test = 5.449089562231929 \n",
      "\n",
      "For alpha = 3162.2776601683795 MSE train = 5.005535473927995 and MSE test = 5.531477262019079 \n",
      "\n",
      "For alpha = 10000.0 MSE train = 5.16620546159834 and MSE test = 5.659845311241812 \n",
      "\n",
      "For alpha = 31622.776601683792 MSE train = 5.372728888473828 and MSE test = 5.833593681734877 \n",
      "\n",
      "For alpha = 100000.0 MSE train = 5.590885982336834 and MSE test = 6.021637686913811 \n",
      "\n",
      "For alpha = 316227.7660168379 MSE train = 5.793998417921919 and MSE test = 6.199598495817027 \n",
      "\n",
      "For alpha = 1000000.0 MSE train = 5.976418820635239 and MSE test = 6.363623555993796 \n",
      "\n",
      "For alpha = 3162277.6601683795 MSE train = 6.140476657958475 and MSE test = 6.519782972294018 \n",
      "\n",
      "For alpha = 10000000.0 MSE train = 6.297539769492749 and MSE test = 6.680062676329957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(1,7,num=13)\n",
    "\n",
    "mse_rtrain_arr = []\n",
    "mse_rtest_arr = []\n",
    "for i in range(len(alphas)):    \n",
    "        for train, test in kfold.split(X):\n",
    "            X_train, X_test = X[train], X[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "\n",
    "            theta = ridge_regression_theta(X_train, y_train, alphas[i])\n",
    "\n",
    "            y_train_pred = predict_y(X_train,theta)\n",
    "            mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(X_train))\n",
    "            mse_rtrain_arr.append(mse_train)\n",
    "\n",
    "            y_test_pred = predict_y(X_test,theta)\n",
    "            #mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test) + (alphas[i]*np.dot(theta.T, theta))\n",
    "            mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(X_test))\n",
    "            mse_rtest_arr.append(mse_test)\n",
    "\n",
    "        avg_train = np.mean(mse_rtrain_arr)\n",
    "        avg_test = np.mean(mse_rtest_arr)\n",
    "        \n",
    "        print(\"For alpha =\", alphas[i], \"MSE train =\", avg_train, \"and MSE test =\", avg_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed735549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 100.0 MSE train = 4.817405052268734 and MSE test = 5.329589628472194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = alphas[2]\n",
    "\n",
    "mse_rigde_train = []\n",
    "mse_rigde_test = []\n",
    "  \n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    theta = ridge_regression_theta(X_train, y_train, alpha)\n",
    "\n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_rigde_train.append(mse_train)\n",
    "\n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_rigde_test.append(mse_test)\n",
    "\n",
    "avg_train = np.mean(mse_rigde_train)\n",
    "avg_test = np.mean(mse_rigde_test)\n",
    "print(\"For alpha =\", alpha, \"MSE train =\", avg_train, \"and MSE test =\", avg_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d202c",
   "metadata": {},
   "source": [
    "### *Polynomial Transformation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bc7c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7271ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_boston.drop('PRICE', axis = 'columns') #independent variables - doing again to remove the bias term\n",
    "polynomial_converter = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc13db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = polynomial_converter.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd3cd825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 105)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0edef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_value2 = 10\n",
    "kfold2 = KFold(n_splits = kfold_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "13b3c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10.0 MSE train = 2.559261364639217 and MSE test = 6.249083656434478 \n",
      "\n",
      "For alpha = 31.622776601683793 MSE train = 2.5999282954046663 and MSE test = 6.262200614378964 \n",
      "\n",
      "For alpha = 100.0 MSE train = 2.6419784656587413 and MSE test = 6.308673099080007 \n",
      "\n",
      "For alpha = 316.22776601683796 MSE train = 2.682513763168582 and MSE test = 6.3648799557806806 \n",
      "\n",
      "For alpha = 1000.0 MSE train = 2.723525020955895 and MSE test = 6.392827172077984 \n",
      "\n",
      "For alpha = 3162.2776601683795 MSE train = 2.7669402266765752 and MSE test = 6.382719705351222 \n",
      "\n",
      "For alpha = 10000.0 MSE train = 2.811273369978179 and MSE test = 6.346089900241313 \n",
      "\n",
      "For alpha = 31622.776601683792 MSE train = 2.856065832263635 and MSE test = 6.29316916370869 \n",
      "\n",
      "For alpha = 100000.0 MSE train = 2.902335508632548 and MSE test = 6.222685349042283 \n",
      "\n",
      "For alpha = 316227.7660168379 MSE train = 2.950551785361065 and MSE test = 6.12369377720346 \n",
      "\n",
      "For alpha = 1000000.0 MSE train = 3.006223592036053 and MSE test = 5.995893059839103 \n",
      "\n",
      "For alpha = 3162277.6601683795 MSE train = 3.0804157011371274 and MSE test = 5.88598245512108 \n",
      "\n",
      "For alpha = 10000000.0 MSE train = 3.1769642028306504 and MSE test = 5.835792486060784 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_train_poly = []\n",
    "mse_test_poly = []\n",
    "for i in range(len(alphas)):    \n",
    "        for train, test in kfold2.split(poly_features):\n",
    "            X_train, X_test = poly_features[train], poly_features[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "\n",
    "            theta = ridge_regression_theta(X_train, y_train, alphas[i])\n",
    "\n",
    "            y_train_pred = predict_y(X_train,theta)\n",
    "            mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "            mse_train_poly.append(mse_train)\n",
    "\n",
    "            y_test_pred = predict_y(X_test,theta)\n",
    "            mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "            mse_test_poly.append(mse_test)\n",
    "\n",
    "        avg_train = np.mean(mse_train_poly)\n",
    "        avg_test = np.mean(mse_test_poly)\n",
    "        \n",
    "        print(\"For alpha =\", alphas[i], \"MSE train =\", avg_train, \"and MSE test =\", avg_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d19f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 100.0 MSE train = 4.335546223152926 and MSE test = 5.233512857337233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_poly = 10000000\n",
    "\n",
    "mse_rtrain_poly = []\n",
    "mse_rtest_poly = []\n",
    "  \n",
    "for train, test in kfold2.split(X):\n",
    "    X_train, X_test = poly_features[train], poly_features[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    theta = ridge_regression_theta(X_train, y_train, alpha_poly)\n",
    "\n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_rtrain_poly.append(mse_train)\n",
    "\n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_rtest_poly.append(mse_test)\n",
    "\n",
    "avg_train = np.mean(mse_rtrain_poly)\n",
    "avg_test = np.mean(mse_rtest_poly)\n",
    "print(\"For alpha =\", alpha, \"MSE train =\", avg_train, \"and MSE test =\", avg_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba2daa",
   "metadata": {},
   "source": [
    "### *Gradient Descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a6429cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_wb = df_boston.drop('PRICE', axis = 'columns') #independent variables - doing again to remove the bias term\n",
    "\n",
    "X_wb = X_wb.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6d08b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent function\n",
    "def gd_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        gradient = (2/len(X))*(X.T.dot(X.dot(theta) - y))\n",
    "        #print(gradient)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8fbc365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.528110235652584 and MSE test = 5.828664402055861 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gd_train = []\n",
    "mse_gd_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gd_train.append(mse_train)\n",
    "   \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gd_test.append(mse_test)\n",
    "\n",
    "avg_train_gd = np.mean(mse_gd_train)\n",
    "avg_test_gd = np.mean(mse_gd_test)\n",
    "print(\"MSE train =\", avg_train_gd, \"and MSE test =\", avg_test_gd, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8850004",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Ridge Regularization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ddfe076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge gradient\n",
    "def ridge_gradient(X, y, y_pred, theta, alpha):\n",
    "    ridge_gr = -(2/len(y)) * X.T.dot(y - y_pred) + alpha*theta    #do we iterate this with all the lambas?\n",
    "    return ridge_gr\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_ridge_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta)     #should this be here?\n",
    "        gradient = ridge_gradient(X, y, y_predicted, theta, 0.0001)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0027099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.5281104585981 and MSE test = 5.828224484248052 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gdr_train = []\n",
    "mse_gdr_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_ridge_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdr_train.append(mse_train)\n",
    "    \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdr_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdr = np.mean(mse_gdr_train)\n",
    "avg_test_gdr = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e5330",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Lasso Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "80b54ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso gradient\n",
    "def lasso_gradient(X, y, y_pred, theta):\n",
    "    lasso_gr = -(2/len(y)) * X.T.dot(y - y_pred) + np.sign(theta)   \n",
    "    return lasso_gr\n",
    "\n",
    "#gradient descent function with lasso gradient\n",
    "def gd_lasso_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta)     #should this be here?\n",
    "        gradient = lasso_gradient(X, y, y_predicted, theta)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7d153f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.5281104585981 and MSE test = 5.828224484248052 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gdl_train = []\n",
    "mse_gdl_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_lasso_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdl_train.append(mse_train)\n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdl_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdl = np.mean(mse_gdr_train)\n",
    "avg_test_gdl = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5594ce",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Elastic Net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge gradient\n",
    "def elastic_gradient(X, y, y_pred, theta, alpha):\n",
    "    elastic_gd = -(2/len(y)) * X.T.dot(y - y_pred)  \n",
    "    return elastic_gd\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_elastic_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta\n",
    "        gradient = elastic_gradient(X, y, y_predicted, theta, 0.0001)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_gde_train = []\n",
    "mse_gde_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    initial_theta = np.random.randn(X.shape[1]) \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    theta = gd_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdl_train.append(mse_train)\n",
    "    \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdl_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdl = np.mean(mse_gdr_train)\n",
    "avg_test_gdl = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fe74b",
   "metadata": {},
   "source": [
    "### Which model will I choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437956e",
   "metadata": {},
   "source": [
    "for all the models you've created so far, which one performed best and why did it perform best. What made it perform better than the others. What were it's parameters. Why would you choose it over the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610ab41",
   "metadata": {},
   "source": [
    "## Lab Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ea133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve -> AUC curve\n",
    "\n",
    "\n",
    "#going over logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e1a5c",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dc6a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#logistic - likelihood (gradient ascent), negative likelihood (gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b799b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xplore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c5286",
   "metadata": {},
   "source": [
    "In the assignment, you will use gradient ascent to find the weights for the\n",
    "logistic regression problem and apply it to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79819d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial hyperparameters\n",
    "thr = 0.5      #threshold\n",
    "lr = 0.5       #learning rate\n",
    "n_iters = 5000  #number of iterations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45350d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the test dataset, determine the:\n",
    "# Precision\n",
    "# Recall\n",
    "# F1 Score\n",
    "# Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11779cd6",
   "metadata": {},
   "source": [
    "6. Plot the value of the log-likelihood (the objective function) on every 100th iteration of your gradient ascent, with the iteration number on the horizontal axis and the objective value on the vertical axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f02f8",
   "metadata": {},
   "source": [
    "7. Use the test set as a validation set and see if you can find a better setting of the hyperparameters. Report the best values you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
