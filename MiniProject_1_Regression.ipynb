{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82b5e01",
   "metadata": {},
   "source": [
    "#### Applied Machine Learning - Mini Project 1 (Tasnim Ahmed, ta1743)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f141ae",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca7cedd",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815741ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50045f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68598fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa7753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the data in a dataframe for readability\n",
    "df_boston = pd.DataFrame(boston.data, columns=boston.feature_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9fa31",
   "metadata": {},
   "source": [
    "Based on the information below we can tell that there no non-empty cells, thus, we  don't need to pre-process the data to fix any empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad847b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47f3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()  #prints out the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d196db7",
   "metadata": {},
   "source": [
    "Below we label the targer variable (y) as 'PRICE' because this is what we will be predicting in our models later for the testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f987590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston['PRICE'] = boston.target   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e703c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()  #checking the dataset after adding the target label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108e0d1",
   "metadata": {},
   "source": [
    "The table below gives the statistics(mean, median and five-number summary) of all the features of our chosen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690685c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db033bd3",
   "metadata": {},
   "source": [
    "### Splitting Data: Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d90b4",
   "metadata": {},
   "source": [
    "Before starting with implementing and testing our models we need to split our data into training and testing sets. We split them because the training sets are used to estimte the parameters of the model and then we implement those parameters on our testing set to check if our model works correctly or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ada547",
   "metadata": {},
   "source": [
    "Below we are separating the independent variables and dependent variables into X and y because functions as an input value whereas y is the output value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f664827e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PRICE'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_boston\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPRICE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#independent variables\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df_boston[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRICE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/aml/lib/python3.9/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PRICE'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X = df_boston.drop('PRICE', axis = 'columns') #independent variables\n",
    "y = df_boston['PRICE']  #dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c40eb",
   "metadata": {},
   "source": [
    "<img src=\"https://ichef.bbci.co.uk/images/ic/1200xn/p0cx7wkx.png\" alt=\"linear regression foundation\" style=\"height: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b3b17",
   "metadata": {},
   "source": [
    "Below we appending ones to the matrix of independendent variable, because the 1s are the bias feature of \n",
    "each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(arr = np.ones([X.shape[0], 1]).astype(int), values = X, axis= 1)\n",
    "X.shape #adding the 1s to our X increases the size of our columns by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4768a58",
   "metadata": {},
   "source": [
    "For the linear regression models the KFold splitting technique is implemented because this techniques results in a less biased model compare to other methods. KFold ensures that every observation from the original dataset has the chance of appearing in training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bc4f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold_value = 5\n",
    "kfold = KFold(n_splits = kfold_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75807c05",
   "metadata": {},
   "source": [
    "### Error Calculation: Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e697a",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-media-1.freecodecamp.org/images/hmZydSW9YegiMVPWq2JBpOpai3CejzQpGkNG\" alt=\"linear regression foundation\" style=\"height: 100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3806c1",
   "metadata": {},
   "source": [
    "For the linear regression models we compare the models based on the MSE values, which is the averages squared difference between the estimates values and the actual value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c3605",
   "metadata": {},
   "source": [
    "### *Closed form solution*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96b49e",
   "metadata": {},
   "source": [
    "The simplest form of linear regression model is the closed form solution model. We can obtain the optimal parameters by using the normal equation, which is derived by taking the derivate of the linear regression equation with respect to the parameters (theta/weight) and setting it to zero and making theta the subject of the equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c9ecf",
   "metadata": {},
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/Untitled-drawing-1-10.png\" alt=\"linear regression foundation\" style=\"height: 150px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2015097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffdda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Form MSE Values\n",
      "Average training RMSE: 20.735084629886188\n",
      "Average testing RMSE: 37.131807467699446\n"
     ]
    }
   ],
   "source": [
    "mse_train_arr = []    # An array that stores the value of training set mse of the 5 iterations of the kfolds\n",
    "mse_test_arr = []     # An array that stores the value of testing set mse of the 5 iterations of the kfolds\n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]    # splitting the X into training and test based on the indices\n",
    "    y_train, y_test = y[train], y[test]    # splitting the y into training and test based on the indices\n",
    "    \n",
    "    theta = normal_equation(X_train, y_train)    # getting the optimal theta with the normal equation\n",
    "    \n",
    "    y_train_pred = np.dot(X_train,theta)       # predicting the training set values with the optimal theta\n",
    "    mse_train = sum((y_train_pred - y_train)**2)/len(y_train)   # calculating the mse of the predicted values\n",
    "    mse_train_arr.append(mse_train)           # at each fold the mse values are appended to the array\n",
    "    \n",
    "    y_test_pred = np.dot(X_test,theta)         # predicting the training set values with the optimal theta\n",
    "    mse_test = sum((y_test_pred - y_test)**2)/len(y_test)     # calculating the mse of the predicted values\n",
    "    mse_test_arr.append(mse_test)            # at each kfold the mse values are appended to the array\n",
    "\n",
    "\n",
    "avg_train_closed = np.mean(mse_train_arr)  # taking the average of the training mse values of each fold\n",
    "avg_test_closed = np.mean(mse_test_arr)    # taking the average of the testing mse values of each fold\n",
    "print(\"Closed Form MSE Values\")\n",
    "print(\"Average training RMSE:\", avg_train_closed)\n",
    "print(\"Average testing RMSE:\", avg_test_closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b49cc",
   "metadata": {},
   "source": [
    "### *Ridge Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4353c4",
   "metadata": {},
   "source": [
    "Ridge regression is a model tuning method that is used to work on data that suffers from multicollinearity. s a statistical concept where several independent variables in a model are correlated and such is the case for our dataset. Thus, the ridge regression closed form equation adds a regularization term to control the magnitude of the coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3afe2c7",
   "metadata": {},
   "source": [
    "<img src=\"https://vitalflux.com/wp-content/uploads/2022/04/Ridge-regression-cost-function-2.png\" alt=\"linear regression foundation\" style=\"height: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc45a7f",
   "metadata": {},
   "source": [
    "λ given here is denoted by an alpha parameter in the ridge function. So, by changing the values of alpha, we are controlling the penalty term. The higher the values of alpha, the bigger is the penalty and therefore the magnitude of coefficients is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9233f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_theta(X, y, alpha):\n",
    "    I = np.identity(X.shape[1])\n",
    "    I[0][0] = 0  \n",
    "    theta = np.linalg.inv(X.T.dot(X) + alpha*I).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2f9c6",
   "metadata": {},
   "source": [
    "The function below is used by 2 models: Ridge Regression Closed Form and Polynomial Feature Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb187f1",
   "metadata": {},
   "source": [
    "The function below uses the ridge regression closed equation to get the optimal theta, which is then used to predict the y values of the training and the testing. The predicted values are then compared with the actual values with the MSE formula. The average of the MSE is returned, since the MSE value if calculated over the given number of folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a14ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_model(X, y, alpha, kfold_value):\n",
    "    \n",
    "    mse_train_arr = []   # An array that stores the value of training set mse of the iterations of the kfolds\n",
    "    mse_test_arr = []    # An array that stores the value of testing set mse of the 5 iterations of the kfolds\n",
    "    \n",
    "    kfold = KFold(n_splits = kfold_value)\n",
    "    for train, test in kfold.split(X):\n",
    "            X_train, X_test = X[train], X[test]    # splitting the X into train and test based on the indices\n",
    "            y_train, y_test = y[train], y[test]    # splitting the y into train and test based on the indices\n",
    "\n",
    "            theta = ridge_regression_theta(X_train, y_train, alpha) # getting the optimal theta with the ridge normal equation\n",
    "\n",
    "            y_train_pred = np.dot(X_train,theta)   # predicting the training set values with the optimal theta\n",
    "            mse_train = sum((y_train_pred - y_train)**2)/len(y_train) # calculating the mse of the predicted values\n",
    "            mse_train_arr.append(mse_train)      # at each fold the mse values are appended to the array\n",
    "\n",
    "            y_test_pred = np.dot(X_test,theta)     # predicting the testing set values with the optimal theta\n",
    "            mse_test = sum((y_test_pred - y_test)**2)/len(y_test) # calculating the mse of the predicted values\n",
    "            mse_test_arr.append(mse_test)        # at each fold the mse values are appended to the array\n",
    "            \n",
    "    return [np.mean(mse_train_arr),np.mean(mse_test_arr)]   #returning the average mse of all the values stored in each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d56dbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Closed Form MSE Values \n",
      "\n",
      "For alpha = 10.0 MSE train = 22.233497098506415 and MSE test = 33.00581779365572\n",
      "For alpha = 31.622776601683793 MSE train = 22.646664882622368 and MSE test = 31.31644662630067\n",
      "For alpha = 100.0 MSE train = 23.609927954690335 and MSE test = 29.615220097335122\n",
      "For alpha = 316.22776601683796 MSE train = 25.37477599577732 and MSE test = 29.799581632087712\n",
      "For alpha = 1000.0 MSE train = 27.757850173242883 and MSE test = 32.079625300307\n",
      "For alpha = 3162.2776601683795 MSE train = 31.248743716769876 and MSE test = 36.39681833044761\n",
      "For alpha = 10000.0 MSE train = 37.18780782673681 and MSE test = 43.49654119663741\n",
      "For alpha = 31622.776601683792 MSE train = 46.06017879697656 and MSE test = 53.06436386051123\n",
      "For alpha = 100000.0 MSE train = 53.761145655011774 and MSE test = 60.55406028295456\n",
      "For alpha = 316227.7660168379 MSE train = 58.309269724671616 and MSE test = 64.65441014932233\n",
      "For alpha = 1000000.0 MSE train = 61.18118612491925 and MSE test = 67.38991217860956\n",
      "For alpha = 3162277.6601683795 MSE train = 63.43047506708822 and MSE test = 69.97421978486146\n",
      "For alpha = 10000000.0 MSE train = 67.01944574854967 and MSE test = 74.2724612406835\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(1,7,num=13)   # array that has all the lamba/alpha values that controls the penalty term\n",
    "\n",
    "print(\"Ridge Regression Closed Form MSE Values\", \"\\n\")\n",
    "\n",
    "kfold_value = 10   # for ridge regression we create 10 fold for splitting the data into training and testing sets\n",
    "for i in range(len(alphas)): #iterations over all the alpha values in the array\n",
    "    mse = ridge_regression_model(X, y, alphas[i], kfold_value) # calls the ridge regression function to get mse for each alpha\n",
    "    print(\"For alpha =\", alphas[i], \"MSE train =\", mse[0], \"and MSE test =\", mse[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2013f",
   "metadata": {},
   "source": [
    "The best value part amongst all the alphas is the value given by alpha = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed735549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 100.0 MSE train = 23.609927954690335 and MSE test = 29.615220097335122 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_ridge = alphas[2]   #the best alpha was chosen by checking which gave the least MSE of testing set\n",
    "rr_mse = ridge_regression_model(X, y, alpha_ridge, kfold_value) \n",
    "print(\"For alpha =\", alpha_ridge, \"MSE train =\", rr_mse[0], \"and MSE test =\", rr_mse[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d202c",
   "metadata": {},
   "source": [
    "### *Polynomial Transformation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9f362",
   "metadata": {},
   "source": [
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/machine-learning-polynomial-regression.png\" alt=\"linear regression foundation\" style=\"height: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24190aac",
   "metadata": {},
   "source": [
    "In polynomial transformation model is a type of feature engineering that is done by creating new input features based on the already existing features. By generating polynomial features, we can uncover potential new relationships between the features and the target and improve the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7271ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures  # importing the skelpolymomial features \n",
    "\n",
    "X_new = df_boston.drop('PRICE', axis = 'columns') #independent variables (creating again to remove the bias term)\n",
    "polynomial_converter = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba1af9",
   "metadata": {},
   "source": [
    "The “degree” of the polynomial is used to control the number of features added, e.g. a degree of 2 will add one new variables for each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcc13db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 105)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = polynomial_converter.fit_transform(X_new) # independent variables after polynomial transformation\n",
    "poly_features.shape   # the number of feature increases with the addiiton of polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8f5ff",
   "metadata": {},
   "source": [
    "Even for polynomial transformation model we use the ridge regression closed form equation to find the optimal theta. Because the number of features has increased, thus, we still have the issue of multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01560c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Feature MSE Values \n",
      "\n",
      "For alpha = 10.0 MSE train = 6.588341672438196 and MSE test = 59.52508999693248\n",
      "For alpha = 31.622776601683793 MSE train = 7.0171020195134926 and MSE test = 61.41648539887863\n",
      "For alpha = 100.0 MSE train = 7.481646104649838 and MSE test = 65.55557807515319\n",
      "For alpha = 316.22776601683796 MSE train = 7.914053076924398 and MSE test = 70.36686130408066\n",
      "For alpha = 1000.0 MSE train = 8.387386360419693 and MSE test = 71.78516200647466\n",
      "For alpha = 3162.2776601683795 MSE train = 8.953319864238308 and MSE test = 68.6881547247963\n",
      "For alpha = 10000.0 MSE train = 9.51761867834638 and MSE test = 62.86987074418263\n",
      "For alpha = 31622.776601683792 MSE train = 10.093060417761679 and MSE test = 55.99478374454818\n",
      "For alpha = 100000.0 MSE train = 10.756066634404032 and MSE test = 48.22101981108817\n",
      "For alpha = 316227.7660168379 MSE train = 11.502928036371761 and MSE test = 38.595444435393986\n",
      "For alpha = 1000000.0 MSE train = 12.747525283996191 and MSE test = 30.068171402220532\n",
      "For alpha = 3162277.6601683795 MSE train = 15.25087566763367 and MSE test = 30.07508919273875\n",
      "For alpha = 10000000.0 MSE train = 18.882249988234747 and MSE test = 34.53169330515347\n"
     ]
    }
   ],
   "source": [
    "print(\"Polynomial Feature MSE Values\", \"\\n\")\n",
    "\n",
    "poly_kfold_value = 10 # for ridge regression we create 10 fold for splitting the data into training and testing sets\n",
    "for i in range(len(alphas)): # iterate over all the values of alpha that was declared earlier\n",
    "    # calls the ridge regression function to get mse for each alpha\n",
    "    mse = ridge_regression_model(poly_features, y, alphas[i], poly_kfold_value) \n",
    "    print(\"For alpha =\", alphas[i], \"MSE train =\", mse[0], \"and MSE test =\", mse[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d19f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 1000000.0 MSE train = 12.747525283996191 and MSE test = 30.068171402220532 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_poly = alphas[10] #the best alpha was chosen by checking which gave the least MSE test\n",
    "poly_mse = ridge_regression_model(poly_features, y, alpha_poly, poly_kfold_value)\n",
    "print(\"For alpha =\", alpha_poly, \"MSE train =\", poly_mse[0], \"and MSE test =\", poly_mse[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba2daa",
   "metadata": {},
   "source": [
    "### *Gradient Descent*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2007f",
   "metadata": {},
   "source": [
    "<img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/gradient-descent-in-machine-learning1.png\" alt=\"linear regression foundation\" style=\"height: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032944f",
   "metadata": {},
   "source": [
    "Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function, which will minimize a cost function as far as possible. The differentiable function here is the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f99a5f",
   "metadata": {},
   "source": [
    "In gradient descent we randomly initialize the parameters (theta) and then iteratively reach the local/global minima of the derivative of the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde1fad",
   "metadata": {},
   "source": [
    "For gradient descent models we scale the data to ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6429cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "X_wb = df_boston.drop('PRICE', axis = 'columns') #independent variables - doing again to remove the bias term\n",
    "X_wb = X_wb.to_numpy()   #converting the dataframe to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ea1e4",
   "metadata": {},
   "source": [
    "The function below is used by 4 gradient descent models: Batch DG, GD with Ridge Regularization, GD with Lasso Regularization and GD with Elastic Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d21a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_value = 5  # using 5 folds to split the data\n",
    "kfold = KFold(n_splits = kfold_value)\n",
    "\n",
    "def gradient_descent_mse(X, y, model_name):\n",
    "    mse_train_arr = []  # An array that stores the value of training set mse of the iterations of the kfolds\n",
    "    mse_test_arr = []   # An array that stores the value of testing set mse of the iterations of the kfolds\n",
    "    \n",
    "    for train, test in kfold.split(X):\n",
    "        X_train, X_test = X[train], X[test]   # splitting the X into train and test based on the indices\n",
    "        y_train, y_test = y[train], y[test]   # splitting the y into train and test based on the indices\n",
    "    \n",
    "        #Initiliazing the parameters\n",
    "        learning_rate = 0.1           # the learning rate\n",
    "        n_iterations = 1000           # number of iterations of gradient descent for finding the minima\n",
    "    \n",
    "        # Scaling the training data  \n",
    "        # the data is transformed without the bias because if bias is added then it become zero\n",
    "        sc = StandardScaler()\n",
    "        X_tr_transform = sc.fit_transform(X_train)\n",
    "        # adding the bias feature\n",
    "        X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "        theta = np.random.randn(X_tr_transform.shape[1])  # initiaiting with randomized parameters\n",
    "        \n",
    "        \n",
    "        # getting the optimal theta with the appropriate based on the given model_name\n",
    "        if model_name == \"gradient_descent\":\n",
    "            theta = gd_theta(X_tr_transform , y_train, theta, learning_rate, n_iterations)\n",
    "        elif model_name == \"ridge_gradient\":\n",
    "            theta = gd_ridge_theta(X_tr_transform , y_train, theta, learning_rate, n_iterations)\n",
    "        elif model_name == \"lasso_gradient\":\n",
    "            theta = gd_lasso_theta(X_tr_transform , y_train, theta, learning_rate, n_iterations)\n",
    "        elif model_name == \"elastic_gradient\":\n",
    "            theta = gd_elastic_theta(X_tr_transform , y_train, theta, learning_rate, n_iterations)\n",
    "            \n",
    "\n",
    "        y_train_pred = np.dot(X_tr_transform,theta) # predicting the training set values with the optimal theta\n",
    "        mse_train = sum((y_train_pred - y_train)**2)/len(y_train) # calculating the mse of the predicted values\n",
    "        mse_train_arr.append(mse_train) # at each fold the mse values are appended to the array\n",
    "        \n",
    "        # Scaling the testing data  \n",
    "        X_t_transform = sc.transform(X_test)\n",
    "        X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "        y_test_pred = np.dot(X_t_transform,theta)  # predicting the testing set values with the optimal theta\n",
    "        mse_test = sum((y_test_pred - y_test)**2)/len(y_test) # calculating the mse of the predicted values\n",
    "        mse_test_arr.append(mse_test) # at each fold the mse values are appended to the array\n",
    "        \n",
    "    avg_train = np.mean(mse_train_arr)\n",
    "    avg_test = np.mean(mse_test_arr)   \n",
    "    return [np.mean(mse_train_arr), np.mean(mse_test_arr)] #returning the average mse of all the values stored in each fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbe661",
   "metadata": {},
   "source": [
    "### *Batch Gradient Descent*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e10915",
   "metadata": {},
   "source": [
    "<img src=\"https://www.oreilly.com/api/v2/epubs/9781491962282/files/assets/eq_29.png\" alt=\"linear regression foundation\" style=\"height: 150px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf63a57",
   "metadata": {},
   "source": [
    "Batch gradient descent finds the optimal paramaters for all the features at ones instead of finding them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d08b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch gradient descent function\n",
    "def gd_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):   # iterating over the given number of iterations\n",
    "        gradient = (2/len(X))*(X.T.dot(X.dot(theta) - y))   # the coded version of the above formula\n",
    "        theta = theta - lrate*gradient  #updating the theta at each iteration\n",
    "    return theta   #returning the optimal theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97e03dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 20.735084633315125 and MSE test = 37.13201479719004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_mse = gradient_descent_mse(X_wb, y, \"gradient_descent\")\n",
    "print(\"MSE train =\", average_mse[0], \"and MSE test =\", average_mse[1], \"\\n\")  #printing the training and test MSE values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceafe44",
   "metadata": {},
   "source": [
    "In the following models we implement gradient descent with regularization because regularization minimizes the validation loss and tries to improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8850004",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Ridge Regularization*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f688745",
   "metadata": {},
   "source": [
    "In this model we add the l2 penalty regularization, same as the earlier ridge regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfe076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge gradient\n",
    "def ridge_gradient(X, y, y_pred, theta, alpha):\n",
    "    ridge_gr = -(2/len(y)) * X.T.dot(y - y_pred) + alpha*theta  # the coded formula for ridge regularization\n",
    "    return ridge_gr\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_ridge_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = np.dot(X,theta)  # predicting the y values with the given/updated theta\n",
    "        gradient = ridge_gradient(X, y, y_predicted, theta, 0.0001)  # the gradient is caculated with ridge regularization\n",
    "        theta = theta - lrate*gradient  # updating the theta at each iteration\n",
    "    return theta   # returning the optimal theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fe4a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_wb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m average_mse_ridge \u001b[38;5;241m=\u001b[39m gradient_descent_mse(\u001b[43mX_wb\u001b[49m, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mridge_gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE train =\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_mse_ridge[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand MSE test =\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_mse_ridge[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_wb' is not defined"
     ]
    }
   ],
   "source": [
    "average_mse_ridge = gradient_descent_mse(X_wb, y, \"ridge_gradient\")\n",
    "print(\"MSE train =\", average_mse_ridge[0], \"and MSE test =\", average_mse_ridge[1]) #printing the training and test MSE values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e5330",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Lasso Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8a46f",
   "metadata": {},
   "source": [
    "Lasso is short for Least Absolute Shrinkage and Selection Operator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e5b8e",
   "metadata": {},
   "source": [
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq8-1.png\" alt=\"linear regression foundation\" style=\"height: 150px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f13a0",
   "metadata": {},
   "source": [
    "Same as ridge regularization but the penalty term is l1 regularization instead of l2. This model uses shrinkage, where data values are shrunk towards a central point as the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80b54ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso gradient\n",
    "def lasso_gradient(X, y, y_pred, theta):\n",
    "    lasso_gr = -(2/len(y)) * X.T.dot(y - y_pred) + 0.0001*np.sign(theta) #lasso regulariozation formula\n",
    "    return lasso_gr    # return the gradient value with lasso regularization\n",
    "\n",
    "#gradient descent function with lasso gradient\n",
    "def gd_lasso_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):  #iterate over the given number of iterations\n",
    "        y_predicted = np.dot(X,theta)   # predict the y value with given theta \n",
    "        gradient = lasso_gradient(X, y, y_predicted, theta)  # gradient with lasso regularization\n",
    "        theta = theta - lrate*gradient  # updating the theta at each iteration\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4fd61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 20.735084807453443 and MSE test = 37.13017094207288\n"
     ]
    }
   ],
   "source": [
    "average_mse_lasso = gradient_descent_mse(X_wb, y, \"lasso_gradient\")\n",
    "print(\"MSE train =\", average_mse_lasso[0], \"and MSE test =\", average_mse_lasso[1]) #print the test and train MSE values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5594ce",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Elastic Net*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefccdab",
   "metadata": {},
   "source": [
    "Elastic Net is a combination of ridge (l2) and lasso regularization (l1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e0b7a",
   "metadata": {},
   "source": [
    "<img src=\"https://learnerjoy.com/wp-content/uploads/2021/12/image-33.png\" alt=\"linear regression foundation\" style=\"height: 150px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f94554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic gradient\n",
    "def elastic_gradient(X, y, y_pred, theta, alpha):\n",
    "    #gradient with elastic net regularization\n",
    "    elastic_gd = -(2/len(y)) * X.T.dot(y - y_pred) + alpha*theta + 0.0001*np.sign(theta)    \n",
    "    return elastic_gd  #return the gradient\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_elastic_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = np.dot(X,theta)  #predict the values of y with given theta\n",
    "        gradient = elastic_gradient(X, y, y_predicted, theta, 0.0001)  # update the gradient at each iteration\n",
    "        theta = theta - lrate*gradient  #update the theta with the updated theta\n",
    "    return theta  #return the optimal theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f475b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 20.73508754207898 and MSE test = 37.125150486140306\n"
     ]
    }
   ],
   "source": [
    "average_mse_elastic = gradient_descent_mse(X_wb, y, \"elastic_gradient\")\n",
    "print(\"MSE train =\", average_mse_elastic[0], \"and MSE test =\", average_mse_elastic[1]) #print the training and testing MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fe74b",
   "metadata": {},
   "source": [
    "### Which model will is the best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b7942",
   "metadata": {},
   "source": [
    "Our target is here to compare the MSE values of all the models and find the model with the least testing MSE value. Because the model with the least MSE value tells us that the model predicted the values of the testing with less error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "736255c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Form:\n",
      "Average training RMSE: 20.735084629886188 Average testing RMSE: 37.131807467699446 \n",
      "\n",
      "Ridge Regression\n",
      "For alpha = 100.0 MSE train = 23.609927954690335 and MSE test = 29.615220097335122 \n",
      "\n",
      "Polynomial Ridge Regression\n",
      "For alpha = 1000000.0 MSE train = 12.747525283996191 and MSE test = 30.068171402220532 \n",
      "\n",
      "Gradient Descent\n",
      "MSE train = 20.735084633315125 and MSE test = 37.13201479719004 \n",
      "\n",
      "Gradient Descent with Ridge Regularization\n",
      "MSE train = 20.735086620270124 and MSE test = 37.12684732537699 \n",
      "\n",
      "Gradient Descent with Lasso Regularization\n",
      "MSE train = 20.735084807453443 and MSE test = 37.13017094207288 \n",
      "\n",
      "Gradient Descent with Elastic Regularization\n",
      "MSE train = 20.73508754207898 and MSE test = 37.125150486140306 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Closed Form:\")\n",
    "print(\"Average training RMSE:\", avg_train_closed, \"Average testing RMSE:\", avg_test_closed, \"\\n\")\n",
    "print(\"Ridge Regression\")\n",
    "print(\"For alpha =\", alpha_ridge, \"MSE train =\", rr_mse[0], \"and MSE test =\", rr_mse[1], \"\\n\")\n",
    "print(\"Polynomial Ridge Regression\")\n",
    "print(\"For alpha =\", alpha_poly, \"MSE train =\", poly_mse[0], \"and MSE test =\", poly_mse[1], \"\\n\")\n",
    "print(\"Gradient Descent\")\n",
    "print(\"MSE train =\", average_mse[0], \"and MSE test =\", average_mse[1], \"\\n\")\n",
    "print(\"Gradient Descent with Ridge Regularization\")\n",
    "print(\"MSE train =\", average_mse_ridge[0], \"and MSE test =\", average_mse_ridge[1], \"\\n\")\n",
    "print(\"Gradient Descent with Lasso Regularization\")\n",
    "print(\"MSE train =\", average_mse_lasso[0], \"and MSE test =\", average_mse_lasso[1], \"\\n\")\n",
    "print(\"Gradient Descent with Elastic Regularization\")\n",
    "print(\"MSE train =\", average_mse_elastic[0], \"and MSE test =\", average_mse_elastic[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ba88c",
   "metadata": {},
   "source": [
    "From the values above we can tell that <b> Ridge Regression </b> with <b>alpha = 100</b>  is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "417614fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRICE</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "PRICE   -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT     PRICE  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "PRICE    0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0449fb",
   "metadata": {},
   "source": [
    "From the data presented above we can see that see there are multiple correlations amongst the features of our dataset. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large, this results in predicted values being far away from the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437956e",
   "metadata": {},
   "source": [
    "Given the fact that our model is multicollinear, ridge regression is best the suited model because it adds a penalizing term that enhances the least square estimate and prevents the model from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e1a5c",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21e62a",
   "metadata": {},
   "source": [
    "Logistic Regression model is similar to linear regression model, but instead of predicting continous numerical values it converts a real number to a binary value based on probabilty. Thus, it is a model used for binary classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0d00f",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dc6a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer  # we will be working with breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b799b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cancer = load_breast_cancer()          #load the data \n",
    "df_cancer = pd.DataFrame(data_cancer.data, columns=data_cancer.feature_names) #extracting the data in a dataframe for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c210e96",
   "metadata": {},
   "source": [
    "By looking at the shape of the dataframe we can tell that there are 569 rows and 30 columns, which means that there are 569 datapoints and 30 features in this dataset that are printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f6014b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer['TARGET'] = data_cancer.target   # setting our target (dependent) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ea3cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  TARGET  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824943ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer = df_cancer.drop('TARGET', axis = 'columns') #independent variables\n",
    "y_cancer = df_cancer['TARGET']  #dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ca8c7",
   "metadata": {},
   "source": [
    "### Train Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0b72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split  #importing a different splitting technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb30a9",
   "metadata": {},
   "source": [
    "In this section, instead of KFold split we will be usin train_test_split to split our data because we are working with only one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fce1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing set\n",
    "# 80% Training and 20% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 10, test_size = 0.2)\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0919ae",
   "metadata": {},
   "source": [
    "Logistic Regression used gradient descent/ascent method,thus, we scale the data to ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "322ee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the training data\n",
    "sc_cancer = StandardScaler()\n",
    "X_train_tr = sc_cancer.fit_transform(X_train)\n",
    "# Adding the bias feature\n",
    "X_train_tr = np.append(arr = np.ones([X_train_tr.shape[0], 1]).astype(int), values = X_train_tr, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab69f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the testing data\n",
    "X_test_tr = sc_cancer.transform(X_test)\n",
    "# Adding the bias feature\n",
    "X_test_tr = np.append(arr = np.ones([X_test_tr.shape[0], 1]).astype(int), values = X_test_tr, axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f0473",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c4571",
   "metadata": {},
   "source": [
    "1. Find the optimal theta using gradient descent\n",
    "2. Use the optimal theta to calculate y values\n",
    "3. Then use the sigmoid function to calculate the probability of y being 0 or 1 by mapping the real y values to any values between 0 and 1\n",
    "4. Predict y: Use the threshold to classify y as 0 or 1 based on the sigmoid function output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c1c3",
   "metadata": {},
   "source": [
    "The Sigmoid Function is an activation function that maps any real value to 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff35e71",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.cf2.quoracdn.net/main-qimg-6b67bea3311c3429bfb34b6b1737fe0c-lq\" alt=\"logistic regression sigmoid\" style=\"height: 250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d9ba386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(y_pred):\n",
    "    sigmoid = 1/(1+np.exp(-y_pred))\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c585880",
   "metadata": {},
   "source": [
    "The cost function we use in logistic regression is called log loss. We use log loss instead of MSE because in logtic regression we are dealing with binary data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649cce6b",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JmuotVGWJCMR54f0Xh04GQ.png\" alt=\"logistic regression sigmoid\" style=\"height: 350px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eea71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, X , y):                                                \n",
    "    y_probability = sigmoid_function(np.dot(X,theta))         # get the probabilites of y\n",
    "    prob_one_log = y * np.log(y_probability)                  # the cost of y_pred when y = 1\n",
    "    prob_zero_log = (1 - y) * np.log(1 - y_probability)       # the cost of y_pred when y = 0\n",
    "    log_likelihood = prob_one_log + prob_zero_log\n",
    "    return np.mean(log_likelihood)      #return the calculated log_likelihood value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0940c9",
   "metadata": {},
   "source": [
    "#### *Logistic Regression Gradient Descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2566a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_gradient_desent returns the gradient value for a given theta\n",
    "def logistic_gradient_descent(X, y, theta):\n",
    "    y_probability = sigmoid_function(np.dot(X,theta))  # get the probability of y being 0 or 1 using the sigmoid\n",
    "    gradient = (1/len(X)) * np.dot(X.T, (y_probability - y)) #calculate the gradient value\n",
    "    return gradient   #return the gradient\n",
    "\n",
    "def logistic_regression_theta(learning_rate, iterations, X_train, y_train, X_test, y_test):\n",
    "    theta = np.random.randn(X_train.shape[1])  #randmize the initial theta\n",
    "    log_likelihood_train = []   # Array to store training objective function values (QS 6)\n",
    "    log_likelihood_test = []   # Array to store testing objective function values (QS 6)\n",
    "\n",
    "    for i in range(iterations):  #iterate over the given iteration value to find the optimal theta\n",
    "        gradient = logistic_gradient_descent(X_train, y_train, theta)   # call the gradient function\n",
    "        theta = theta - learning_rate*gradient  #update the theta at each iteration\n",
    "        \n",
    "        likelihood_train = 0\n",
    "        likelihood_test = 0\n",
    "        if i%100 == 0:  #calculate the log likelihood value at each 100th iteration (QS 6)\n",
    "            likelihood_train = log_likelihood(theta, X_train, y_train) #calculte the log likelihood training value\n",
    "            log_likelihood_train.append(likelihood_train)    \n",
    "            \n",
    "            likelihood_test = log_likelihood(theta, X_test, y_test)  #calculte the log likelihood testing value\n",
    "            log_likelihood_test.append(likelihood_test)\n",
    "            \n",
    "            \n",
    "    return [theta, log_likelihood_train, log_likelihood_test]  #return the optimal theta and the log-likelihood vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b79819d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta value (w): [-0.79213316 -0.36782369 -0.51798601  0.93419099 -0.9012063   0.00882683\n",
      "  1.19698012 -1.85008752 -2.62496747  1.08796892 -0.1048369  -5.13197966\n",
      "  0.98131519 -1.94446096 -0.98026694 -0.36483449  3.22004328 -1.06532521\n",
      " -2.37231837  2.14993215  3.02677127 -1.61591923 -2.83121534 -2.27476371\n",
      " -0.79931377 -0.34540342  1.09379407 -2.03234494 -0.40488998 -1.67750686\n",
      " -2.69968539]\n"
     ]
    }
   ],
   "source": [
    "#ignore warning\n",
    "np.seterr(divide = 'ignore')\n",
    "\n",
    "#initial hyperparameters\n",
    "threshold = 0.5                                # if the value goes above this then class 1, if below then class 2\n",
    "lr = 0.5                                       # learning rate\n",
    "n_iters = 5000                                 # number of iterations\n",
    "\n",
    "model_theta = logistic_regression_theta(lr, n_iters, X_train_tr, y_train, X_test_tr, y_test)[0]   #send the X_train and y_train\n",
    "print(\"Theta value (w):\", model_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f1001",
   "metadata": {},
   "source": [
    "Using the optimal theta, we then predict the values of y_test using the given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb4cd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values of y_test: [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def predict_y_value(X, theta, threshold):\n",
    "    y_probability = sigmoid_function(np.dot(X,theta))\n",
    "    y_predicted = [1 if i > 0.5 else 0 for i in y_probability]\n",
    "    return y_predicted\n",
    "\n",
    "predicted_values = predict_y_value(X_test_tr, model_theta, threshold)\n",
    "print(\"The predicted values of y_test:\", predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65186336",
   "metadata": {},
   "source": [
    "####  *Accuracy of the Model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb20d63",
   "metadata": {},
   "source": [
    "After predicting the values we check the accuracy of our model with the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95731bbd",
   "metadata": {},
   "source": [
    "<img src=\"https://plat.ai/wp-content/uploads/Table1-2.png.webp\" alt=\"confusion matrix\" style=\"height: 250px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e083655",
   "metadata": {},
   "source": [
    "Confusion Matrix is a table that is used to define the performance of a classification algorithm. It checks the matcing between the predicted values and the actual values. With the help of confusion matrix we can learn the following about our model. \n",
    "    \n",
    "- Precision: What proportion of positive identifications was actually correct?\n",
    "- Recall: What proportion of actual positives was identified correctly?\n",
    "- F1-Score: It uses precision and recall to tell us the model's accuracy on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b36aa3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9594594594594594\n",
      "Recall: 0.9466666666666667\n",
      "F-Measure: 0.9530201342281879\n",
      "Confusion Matrix:\n",
      " [[36  3]\n",
      " [ 4 71]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix:\n",
    "def confusion_matrix(y, y_pred):\n",
    "    tp = tn = fp = fn = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]: #true values\n",
    "            if y_pred[i] == 1:\n",
    "                tp += 1          #true-positive\n",
    "            else:\n",
    "                tn += 1          #true-negative\n",
    "        else: \n",
    "            if y_pred[i] == 1: #false values\n",
    "                fp += 1          #false-positive     \n",
    "            else: \n",
    "                fn += 1          #false-negative\n",
    "            \n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f_measure = 2*precision*recall/(precision + recall)\n",
    "                \n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-Measure:\", f_measure)\n",
    "     \n",
    "    return [[tn, fp], [fn, tp]]\n",
    "\n",
    "cf = np.array(confusion_matrix(y_test, predicted_values))\n",
    "print(\"Confusion Matrix:\\n\", cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5940544",
   "metadata": {},
   "source": [
    "### *Plotting the Log Likelihood Outcome*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0554462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(title, n_iters, data_points):\n",
    "    size = int(n_iters/100)\n",
    "    x_axis = [i*100 for i in range(1, size + 1)]\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch iteration')\n",
    "    plt.ylabel('log-likehood value')\n",
    "    plt.xticks(x_axis)\n",
    "    plt.plot(x_axis, data_points, marker='o')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45350d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_likelihood_train = logistic_regression_theta(lr, n_iters, X_train_tr, y_train, X_test_tr, y_test)[1] \n",
    "plot_graph('Log Likelihood Outcome of Training Set', n_iters, log_likelihood_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab28087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_likelihood_test = logistic_regression_theta(lr, n_iters, X_train_tr, y_train, X_test_tr, y_test)[2] \n",
    "plot_graph('Log Likelihood Outcome of Testing Set', n_iters, log_likelihood_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5da3f",
   "metadata": {},
   "source": [
    "#### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76be129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning\n",
    "np.seterr(divide = 'ignore')\n",
    "\n",
    "#initial hyperparameters\n",
    "threshold_v = 0.4                                # if the value goes above this then class 1, if below then class 2\n",
    "lr_v = 0.5                                       # learning rate\n",
    "n_iters_v = 500                                 # number of iterations\n",
    "\n",
    "model_theta_validate = logistic_regression_theta(lr_v, n_iters_v, X_train_tr, y_train, X_test_tr, y_test)[0]   #send the X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e4f708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values of y_test: [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predicted_values_validate = predict_y_value(X_test_tr, model_theta_validate, threshold_v)\n",
    "print(\"The predicted values of y_test:\", predicted_values_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d64c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9733333333333334\n",
      "Recall: 0.9733333333333334\n",
      "F-Measure: 0.9733333333333334\n",
      "Confusion Matrix:\n",
      " [[37  2]\n",
      " [ 2 73]]\n"
     ]
    }
   ],
   "source": [
    "cf = np.array(confusion_matrix(y_test, predicted_values_validate))\n",
    "print(\"Confusion Matrix:\\n\", cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1fec7",
   "metadata": {},
   "source": [
    "The best parameters are:\n",
    "- Threshold = 0.4\n",
    "- Number of Iterations = 500\n",
    "- Learning Rate = 0.5\n",
    "\n",
    "The metric value enhance when we use the values above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
