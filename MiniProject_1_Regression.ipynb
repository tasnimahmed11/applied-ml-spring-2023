{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82b5e01",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca7cedd",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "815741ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50045f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b68598fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa7753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the data in a dataframe for readability\n",
    "df_boston = pd.DataFrame(boston.data, columns=boston.feature_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad847b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(boston.feature_names)  #printing the feature names to check the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47f3749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()  #prints out the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d196db7",
   "metadata": {},
   "source": [
    "Below we label the targer variable (y) as 'PRICE' because this is what we will be predicting in our models later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f987590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston['PRICE'] = boston.target   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e703c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()  #checking the dataset after adding the target label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108e0d1",
   "metadata": {},
   "source": [
    "Below we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690685c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c68907",
   "metadata": {},
   "source": [
    "Based on the information below we can tell that there no non-empty cells, thus, we  don't need to pre-process the data to fix any empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d5c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  PRICE    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms of the dataset?\n",
    "#Do we take off the features that don't correlate with the target?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db033bd3",
   "metadata": {},
   "source": [
    "### Splitting Data: Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f664827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_boston.drop('PRICE', axis = 'columns') #independent variables\n",
    "y = df_boston['PRICE']  #dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78eb93ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending ones to the matrix of independendent variable\n",
    "X = np.append(arr = np.ones([X.shape[0], 1]).astype(int), values = X, axis= 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bc4f21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold_value = 5\n",
    "kfold = KFold(n_splits = kfold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1bbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What metric should we use to estimate the performance of our linear regression model?\n",
    " \n",
    "#loss {train, validation, test}, accuracy {train, validation, test},\n",
    "#confusion matrix, precision, recall, f1 score, etc. \n",
    "#Many to choose from but check the lab manual for specifics requested per question.\n",
    "\n",
    "\n",
    "#find error - then square it - then mean \n",
    "#yhat = theta * independentvariabel\n",
    "#np.matmul // np.dot(does the same thing upto 2 dimension)\n",
    "#scale th data - preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c3605",
   "metadata": {},
   "source": [
    "### *Closed form solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2015097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return theta\n",
    "\n",
    "def predict_y(X, theta):\n",
    "    return np.dot(X,theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ffdda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training MSE: 4.528110235625727\n",
      "Average testing MSE: 5.828658946215792\n"
     ]
    }
   ],
   "source": [
    "mse_train_arr = []\n",
    "mse_test_arr = []\n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    theta = normal_equation(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_train_arr.append(mse_train)\n",
    "    \n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_test_arr.append(mse_test)\n",
    "\n",
    "\n",
    "avg_train = np.mean(mse_train_arr)\n",
    "avg_test = np.mean(mse_test_arr)\n",
    "print(\"Average training MSE:\", avg_train)\n",
    "print(\"Average testing MSE:\", avg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b49cc",
   "metadata": {},
   "source": [
    "### *Ridge Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9233f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_theta(X, y, alpha):\n",
    "    I = np.identity(X.shape[1])\n",
    "    I[0][0] = 0  \n",
    "    theta = np.linalg.inv(X.T.dot(X) + alpha*I).dot(X.T).dot(y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d56dbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10.0 MSE train = 4.63254342637088 and MSE test = 5.518166280868784 \n",
      "\n",
      "For alpha = 31.622776601683793 MSE train = 4.660283682305299 and MSE test = 5.467538413292376 \n",
      "\n",
      "For alpha = 100.0 MSE train = 4.712657472293112 and MSE test = 5.421555485018982 \n",
      "\n",
      "For alpha = 316.22776601683796 MSE train = 4.790315495620764 and MSE test = 5.411757151120624 \n",
      "\n",
      "For alpha = 1000.0 MSE train = 4.886169923351052 and MSE test = 5.449089562231929 \n",
      "\n",
      "For alpha = 3162.2776601683795 MSE train = 5.005535473927995 and MSE test = 5.531477262019079 \n",
      "\n",
      "For alpha = 10000.0 MSE train = 5.16620546159834 and MSE test = 5.659845311241812 \n",
      "\n",
      "For alpha = 31622.776601683792 MSE train = 5.372728888473828 and MSE test = 5.833593681734877 \n",
      "\n",
      "For alpha = 100000.0 MSE train = 5.590885982336834 and MSE test = 6.021637686913811 \n",
      "\n",
      "For alpha = 316227.7660168379 MSE train = 5.793998417921919 and MSE test = 6.199598495817027 \n",
      "\n",
      "For alpha = 1000000.0 MSE train = 5.976418820635239 and MSE test = 6.363623555993796 \n",
      "\n",
      "For alpha = 3162277.6601683795 MSE train = 6.140476657958475 and MSE test = 6.519782972294018 \n",
      "\n",
      "For alpha = 10000000.0 MSE train = 6.297539769492749 and MSE test = 6.680062676329957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(1,7,num=13)\n",
    "\n",
    "mse_rtrain_arr = []\n",
    "mse_rtest_arr = []\n",
    "for i in range(len(alphas)):    \n",
    "        for train, test in kfold.split(X):\n",
    "            X_train, X_test = X[train], X[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "\n",
    "            theta = ridge_regression_theta(X_train, y_train, alphas[i])\n",
    "\n",
    "            y_train_pred = predict_y(X_train,theta)\n",
    "            mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(X_train))\n",
    "            mse_rtrain_arr.append(mse_train)\n",
    "\n",
    "            y_test_pred = predict_y(X_test,theta)\n",
    "            #mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test) + (alphas[i]*np.dot(theta.T, theta))\n",
    "            mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(X_test))\n",
    "            mse_rtest_arr.append(mse_test)\n",
    "\n",
    "        avg_ridge_train = np.mean(mse_rtrain_arr)\n",
    "        avg_ridge_test = np.mean(mse_rtest_arr)\n",
    "        \n",
    "        print(\"For alpha =\", alphas[i], \"MSE train =\", avg_ridge_train, \"and MSE test =\", avg_ridge_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed735549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 100.0 MSE train = 4.817405052268734 and MSE test = 5.329589628472194 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = alphas[2]\n",
    "\n",
    "mse_rigde_train = []\n",
    "mse_rigde_test = []\n",
    "  \n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    theta = ridge_regression_theta(X_train, y_train, alpha)\n",
    "\n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_rigde_train.append(mse_train)\n",
    "\n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_rigde_test.append(mse_test)\n",
    "\n",
    "avg_ridge2_train = np.mean(mse_rigde_train)\n",
    "avg_ridge2_test = np.mean(mse_rigde_test)\n",
    "print(\"For alpha =\", alpha, \"MSE train =\", avg_ridge2_train, \"and MSE test =\", avg_ridge2_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d202c",
   "metadata": {},
   "source": [
    "### *Polynomial Transformation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc7c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7271ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_boston.drop('PRICE', axis = 'columns') #independent variables - doing again to remove the bias term\n",
    "polynomial_converter = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcc13db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = polynomial_converter.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd3cd825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 105)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0edef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_value2 = 10\n",
    "kfold2 = KFold(n_splits = kfold_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b3c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10.0 MSE train = 2.559261364639217 and MSE test = 6.249083656434478 \n",
      "\n",
      "For alpha = 31.622776601683793 MSE train = 2.5999282954046663 and MSE test = 6.262200614378964 \n",
      "\n",
      "For alpha = 100.0 MSE train = 2.6419784656587413 and MSE test = 6.308673099080007 \n",
      "\n",
      "For alpha = 316.22776601683796 MSE train = 2.682513763168582 and MSE test = 6.3648799557806806 \n",
      "\n",
      "For alpha = 1000.0 MSE train = 2.723525020955895 and MSE test = 6.392827172077984 \n",
      "\n",
      "For alpha = 3162.2776601683795 MSE train = 2.7669402266765752 and MSE test = 6.382719705351222 \n",
      "\n",
      "For alpha = 10000.0 MSE train = 2.811273369978179 and MSE test = 6.346089900241313 \n",
      "\n",
      "For alpha = 31622.776601683792 MSE train = 2.856065832263635 and MSE test = 6.29316916370869 \n",
      "\n",
      "For alpha = 100000.0 MSE train = 2.902335508632548 and MSE test = 6.222685349042283 \n",
      "\n",
      "For alpha = 316227.7660168379 MSE train = 2.950551785361065 and MSE test = 6.12369377720346 \n",
      "\n",
      "For alpha = 1000000.0 MSE train = 3.006223592036053 and MSE test = 5.995893059839103 \n",
      "\n",
      "For alpha = 3162277.6601683795 MSE train = 3.0804157011371274 and MSE test = 5.88598245512108 \n",
      "\n",
      "For alpha = 10000000.0 MSE train = 3.1769642028306504 and MSE test = 5.835792486060784 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_train_poly = []\n",
    "mse_test_poly = []\n",
    "for i in range(len(alphas)):    \n",
    "        for train, test in kfold2.split(poly_features):\n",
    "            X_train, X_test = poly_features[train], poly_features[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "\n",
    "            theta = ridge_regression_theta(X_train, y_train, alphas[i])\n",
    "\n",
    "            y_train_pred = predict_y(X_train,theta)\n",
    "            mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "            mse_train_poly.append(mse_train)\n",
    "\n",
    "            y_test_pred = predict_y(X_test,theta)\n",
    "            mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "            mse_test_poly.append(mse_test)\n",
    "\n",
    "        avg_train_poly = np.mean(mse_train_poly)\n",
    "        avg_test_poly = np.mean(mse_test_poly)\n",
    "        \n",
    "        print(\"For alpha =\", alphas[i], \"MSE train =\", avg_train_poly, \"and MSE test =\", avg_test_poly, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d19f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 10000000 MSE train = 4.335546223152926 and MSE test = 5.233512857337233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_poly = 10000000\n",
    "\n",
    "mse_train2_poly = []\n",
    "mse_test2_poly = []\n",
    "  \n",
    "for train, test in kfold2.split(poly_features):\n",
    "    X_train, X_test = poly_features[train], poly_features[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "\n",
    "    theta = ridge_regression_theta(X_train, y_train, alpha_poly)\n",
    "\n",
    "    y_train_pred = predict_y(X_train,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_train2_poly.append(mse_train)\n",
    "\n",
    "    y_test_pred = predict_y(X_test,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_test2_poly.append(mse_test)\n",
    "\n",
    "avg_train2_poly = np.mean(mse_train2_poly)\n",
    "avg_test2_poly = np.mean(mse_test2_poly)\n",
    "        \n",
    "print(\"For alpha =\", alpha_poly, \"MSE train =\", avg_train2_poly, \"and MSE test =\", avg_test2_poly, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba2daa",
   "metadata": {},
   "source": [
    "### *Gradient Descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6429cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_wb = df_boston.drop('PRICE', axis = 'columns') #independent variables - doing again to remove the bias term\n",
    "X_wb = X_wb.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d08b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent function\n",
    "def gd_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        gradient = (2/len(X))*(X.T.dot(X.dot(theta) - y))\n",
    "        #print(gradient)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fbc365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.52811023592473 and MSE test = 5.8286773730331065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gd_train = []\n",
    "mse_gd_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gd_train.append(mse_train)\n",
    "   \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gd_test.append(mse_test)\n",
    "\n",
    "avg_train_gd = np.mean(mse_gd_train)\n",
    "avg_test_gd = np.mean(mse_gd_test)\n",
    "print(\"MSE train =\", avg_train_gd, \"and MSE test =\", avg_test_gd, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8850004",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Ridge Regularization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddfe076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge gradient\n",
    "def ridge_gradient(X, y, y_pred, theta, alpha):\n",
    "    ridge_gr = -(2/len(y)) * X.T.dot(y - y_pred) + alpha*theta    \n",
    "    return ridge_gr\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_ridge_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta)     #should this be here?\n",
    "        gradient = ridge_gradient(X, y, y_predicted, theta, 0.0001)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0027099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.528110459270828 and MSE test = 5.828228411257612 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gdr_train = []\n",
    "mse_gdr_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_ridge_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdr_train.append(mse_train)\n",
    "    \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdr_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdr = np.mean(mse_gdr_train)\n",
    "avg_test_gdr = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e5330",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Lasso Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80b54ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso gradient\n",
    "def lasso_gradient(X, y, y_pred, theta):\n",
    "    lasso_gr = -(2/len(y)) * X.T.dot(y - y_pred) + np.sign(theta)   \n",
    "    return lasso_gr\n",
    "\n",
    "#gradient descent function with lasso gradient\n",
    "def gd_lasso_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta)     #should this be here?\n",
    "        gradient = lasso_gradient(X, y, y_predicted, theta)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a7d153f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train = 4.528110459270828 and MSE test = 5.828228411257612 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_gdl_train = []\n",
    "mse_gdl_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    initial_theta = np.random.randn(X_tr_transform.shape[1]) \n",
    "    theta = gd_lasso_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdl_train.append(mse_train)\n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdl_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdl = np.mean(mse_gdr_train)\n",
    "avg_test_gdl = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5594ce",
   "metadata": {},
   "source": [
    "### *Gradient Descent with Elastic Net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#ridge gradient\n",
    "def elastic_gradient(X, y, y_pred, theta, alpha):\n",
    "    elastic_gd = -(2/len(y)) * X.T.dot(y - y_pred) + np.sign(theta)   \n",
    "    return elastic_gd\n",
    "\n",
    "#gradient descent function with ridge gradient\n",
    "def gd_elastic_theta(X, y, theta, lrate, n_iter):\n",
    "    for i in range(n_iter):\n",
    "        y_predicted = predict_y(X, theta\n",
    "        gradient = elastic_gradient(X, y, y_predicted, theta, 0.0001)\n",
    "        theta = theta - lrate*gradient\n",
    "    return theta\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mse_gde_train = []\n",
    "mse_gde_test = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X_wb):\n",
    "    X_train, X_test = X_wb[train], X_wb[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    #Initiliazing the parameters\n",
    "    learning_rate = 0.1\n",
    "    n_iterations = 1000\n",
    "    initial_theta = np.random.randn(X.shape[1]) \n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_tr_transform = sc.fit_transform(X_train)\n",
    "    X_tr_transform = np.append(arr = np.ones([X_tr_transform.shape[0], 1]).astype(int), values = X_tr_transform, axis= 1)\n",
    "    \n",
    "    theta = gd_theta(X_tr_transform , y_train, initial_theta, learning_rate, n_iterations)\n",
    "\n",
    "    y_train_pred = predict_y(X_tr_transform ,theta)\n",
    "    mse_train = np.sqrt(sum((y_train_pred - y_train)**2)/len(y_train))\n",
    "    mse_gdl_train.append(mse_train)\n",
    "    \n",
    "    \n",
    "    X_t_transform = sc.transform(X_test)\n",
    "    X_t_transform = np.append(arr = np.ones([X_t_transform.shape[0], 1]).astype(int), values = X_t_transform, axis= 1)\n",
    "\n",
    "    y_test_pred = predict_y(X_t_transform,theta)\n",
    "    mse_test = np.sqrt(sum((y_test_pred - y_test)**2)/len(y_test))\n",
    "    mse_gdl_test.append(mse_test)\n",
    "    \n",
    "\n",
    "avg_train_gdl = np.mean(mse_gdr_train)\n",
    "avg_test_gdl = np.mean(mse_gdr_test)\n",
    "print(\"MSE train =\", avg_train_gdr, \"and MSE test =\", avg_test_gdr, \"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fe74b",
   "metadata": {},
   "source": [
    "### Which model will I choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437956e",
   "metadata": {},
   "source": [
    "for all the models you've created so far, which one performed best and why did it perform best. What made it perform better than the others. What were it's parameters. Why would you choose it over the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e1a5c",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0d00f",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc6a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#logistic - likelihood (gradient ascent), negative likelihood (gradient descent)\n",
    "#use gradient ascent to find the weights for the logistic regression problem and apply it to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b799b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data \n",
    "data_cancer = load_breast_cancer()  \n",
    "\n",
    "#extracting the data in a dataframe for readability\n",
    "df_cancer = pd.DataFrame(data_cancer.data, columns=data_cancer.feature_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c210e96",
   "metadata": {},
   "source": [
    "By looking at the shape of the dataframe we can tell that there are 569 rows and 30 columns, which means that there are 569 datapoints and 30 features in this dataset that are printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f6014b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c96e8baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.feature_names)  #printing the feature names to check the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer['TARGET'] = data_cancer.target   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ea3cdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  TARGET  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "824943ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer = df_cancer.drop('TARGET', axis = 'columns') #independent variables\n",
    "y_cancer = df_cancer['TARGET']  #dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c89c5269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(X_cancer.shape)\n",
    "print(y_cancer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ca8c7",
   "metadata": {},
   "source": [
    "### Train Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fce1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 104, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "322ee5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 31)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the training data\n",
    "sc_cancer = StandardScaler()\n",
    "X_train_tr = sc_cancer.fit_transform(X_train)\n",
    "X_train_tr = np.append(arr = np.ones([X_train_tr.shape[0], 1]).astype(int), values = X_train_tr, axis= 1)\n",
    "X_train_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ab69f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 31)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the testing data\n",
    "X_test_tr = sc_cancer.transform(X_test)\n",
    "X_test_tr = np.append(arr = np.ones([X_test_tr.shape[0], 1]).astype(int), values = X_test_tr, axis= 1)\n",
    "X_test_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f0473",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c1c3",
   "metadata": {},
   "source": [
    "What does the sigmoid function do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d9ba386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(y_pred):  #the activation function \n",
    "    sigmoid = 1/(1+np.exp(y_pred))\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c585880",
   "metadata": {},
   "source": [
    "The cost function we use in logistic regression is called log loss (different from mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9eea71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(theta, X, y):\n",
    "    m = len(X)                                                # get the number of observations \n",
    "    y_probability = sigmoid_function(predict_y(X, theta))     # get the probabilites of y\n",
    "    prob_one_log = y * np.log(y_probability)                  # the cost of y_pred when y = 1\n",
    "    prob_zero_log = (1 - y) * np.log(1 - y_probability)       # the cost of y_pred when y = 0\n",
    "    log_loss = -(1/m) * np.sum(prob_one_log + prob_zero_log)\n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0940c9",
   "metadata": {},
   "source": [
    "What does the gradient ascent function do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97fdac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def logistic_gradient_descent(X, y, theta):\n",
    "    y_probability = sigmoid_function(predict_y(X, theta))\n",
    "    gradient = (1/len(X)) * np.dot(X.T, (y_probability - y))\n",
    "    return gradient\n",
    "\"\"\"\n",
    "\n",
    "def gradient_ascent(X, y, theta):\n",
    "    y_probability = sigmoid(predict_y(X, theta))\n",
    "    ll = np.sum(y*y_probability - np.log(1 + np.exp(y_probability)))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b79819d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 126.27473352 -343.88662653 -185.76365175 -350.97374359 -333.83943019\n",
      " -179.76102495 -319.74452926 -360.8140571  -381.73745225 -187.47698436\n",
      "  -38.01415882 -272.57008051   -5.29777764 -271.86681681 -258.49372038\n",
      "    6.23318845 -196.82019834 -169.8125564  -236.0410654   -36.95485236\n",
      "  -98.55357045 -363.70270462 -201.86302601 -369.02445314 -346.25021503\n",
      " -200.57548195 -307.97199466 -338.85732995 -388.06589965 -204.30084698\n",
      " -194.59843518]\n"
     ]
    }
   ],
   "source": [
    "#suppress warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "#initial hyperparameters\n",
    "threshold = 0.5                                # if the value goes above this then class 1, if below then class 2\n",
    "lr = 0.5                                       # learning rate\n",
    "n_iters = 1000                                 # number of iterations\n",
    "\n",
    "theta = np.zeros(X_train_tr.shape[1])#np.random.randn(X_train_tr.shape[1])    # intializing the theta to random value\n",
    "\n",
    "for i in range(n_iters):\n",
    "    gradient = logistic_gradient_descent(X_train_tr, y_train, theta)   # call the gradient function\n",
    "    theta = theta - lr*gradient\n",
    "\n",
    "\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. report the theta we find in the first iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d89002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Predict the values of y and find the loss\n",
    "\n",
    "#for the test dataset, determine the:\n",
    "# Precision\n",
    "# Recall\n",
    "# F1 Score\n",
    "# Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45350d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot the value of the log-likelihood (the objective function) on every 100th iteration of your gradient ascent, \n",
    "# with the iteration number on the horizontal axis and the objective value on the vertical axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Use the test set as a validation set and see if you can find a better setting of the hyperparameters. \n",
    "# Report the best values you found."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
